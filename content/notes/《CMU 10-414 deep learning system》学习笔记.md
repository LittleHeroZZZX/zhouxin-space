---
title: ã€ŠCMU 10-414 deep learning systemã€‹å­¦ä¹ ç¬”è®°
tags:
  - CUDA
  - æ·±åº¦å­¦ä¹ ç³»ç»Ÿ
date: 2024-05-28T12:24:00+08:00
lastmod: 2024-07-05T14:49:00+08:00
publish: true
dir: notes
slug: notes on cmu 10-414 deep learning system
images:
  - https://pics.zhouxin.space/202406041918872.png?x-oss-process=image/quality,q_90/format,webp
math: "true"
---

# Lecture 1: Introduction and Logistics

## è¯¾ç¨‹çš„ç›®æ ‡

æœ¬è¯¾ç¨‹çš„ç›®æ ‡æ˜¯å­¦ä¹ ç°ä»£æ·±åº¦å­¦ä¹ ç³»ç»Ÿï¼Œäº†è§£åŒ…æ‹¬è‡ªåŠ¨å¾®åˆ†ã€ç¥ç»ç½‘ç»œæ¶æ„ã€ä¼˜åŒ–ä»¥åŠ GPU ä¸Šçš„é«˜æ•ˆæ“ä½œåœ¨å†…çš„æŠ€æœ¯çš„åº•å±‚åŸç†ã€‚ä½œä¸ºå®è·µï¼Œæœ¬è¯¾ç¨‹å°†å®ç°ä¸€ä¸ª needleï¼ˆdeep learning libraryï¼‰åº“ï¼Œç±»ä¼¼ PyTorchã€‚

## ä¸ºä»€ä¹ˆå­¦ä¹ æ·±åº¦å­¦ä¹ ç³»ç»Ÿï¼Ÿ

ä¸ºä»€ä¹ˆå­¦ä¹ ï¼Ÿæ·±åº¦å­¦ä¹ è¿™ä¸€æ¦‚å¿µå¾ˆæ—©å°±å­˜åœ¨äº†ï¼Œä½†ç›´åˆ° PyTorchã€TensorFlow æ­¤ç±»ç°ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶å‘å¸ƒï¼Œæ·±åº¦å­¦ä¹ æ‰å¼€å§‹è¿…é€Ÿå‘å±•ã€‚ç®€å•æ˜“ç”¨çš„è‡ªåŠ¨å·®åˆ†åº“æ˜¯æ·±åº¦å­¦ä¹ å‘å±•çš„æœ€å¤§åŠ¨åŠ›ã€‚

é™¤äº†ä½¿ç”¨è¿™äº›åº“ï¼Œæˆ‘ä»¬ä¸ºä»€ä¹ˆè¿˜è¦å­¦ä¹ æ·±åº¦å­¦ä¹ ç³»ç»Ÿï¼Ÿ

- ä¸ºäº†æ„å»ºæ·±åº¦å­¦ä¹ ç³»ç»Ÿ  
å¦‚æœæƒ³è¦ä»äº‹æ·±åº¦å­¦ä¹ ç³»ç»Ÿçš„å¼€å‘ï¼Œé‚£æ¯«æ— ç–‘é—®å¾—å…ˆå­¦ä¹ å®ƒã€‚ç›®å‰æ·±åº¦å­¦ä¹ æ¡†æ¶å¹¶æ²¡å®Œå…¨æˆç†Ÿï¼Œè¿˜æœ‰å¾ˆå¤šå¼€å‘æ–°åŠŸèƒ½ï¼Œä¹ƒè‡³æ–°çš„æ¡†æ¶çš„æœºä¼šã€‚

- ä¸ºäº†èƒ½å¤Ÿæ›´é«˜æ•ˆåœ°ä½¿ç”¨ç°æœ‰ç³»ç»Ÿ  
äº†è§£ç°æœ‰ç³»ç»Ÿçš„å†…éƒ¨å®ç°ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬å†™å‡ºæ›´åŠ é«˜æ•ˆçš„æ·±åº¦å­¦ä¹ ä»£ç ã€‚å¦‚æœæƒ³è¦æé«˜è‡ªå®šä¹‰ç®—å­çš„æ•ˆç‡ï¼Œé‚£å¿…é¡»å…ˆäº†è§£ç›¸å…³æ“ä½œæ˜¯å¦‚ä½•å®ç°çš„ã€‚

- æ·±åº¦å­¦ä¹ ç³»ç»Ÿæœ¬èº«å°±å¾ˆæœ‰è¶£  
å°½ç®¡è¿™ä¸ªç³»ç»Ÿçœ‹ä¸Šå»å¾ˆå¤æ‚ï¼Œä½†æ˜¯å…¶æ ¸å¿ƒç®—æ³•çš„åŸç†ç¡®å®ç›¸å½“ç®€å•çš„ã€‚ä¸¤åƒè¡Œå·¦å³çš„ä»£ç ï¼Œå°±å¯ä»¥å†™å‡ºä¸€ä¸ªæ·±åº¦å­¦ä¹ åº“ã€‚

## é¢„å¤‡çŸ¥è¯†

- systems programming
- çº¿æ€§ä»£æ•°
- å…¶ä»–æ•°å­¦çŸ¥è¯†ï¼šè®¡ç®—ã€æ¦‚ç‡ã€ç®€å•çš„è¯æ˜
- Python å’Œ C++ ç»éªŒ
- æœºå™¨å­¦ä¹ çš„ç›¸å…³ç»éªŒ

# Lecture 2: ML Refresher & Softmax Regression

## æœºå™¨å­¦ä¹ åŸºç¡€

æ·±åº¦å­¦ä¹ æ˜¯ç”±æ•°æ®é©±åŠ¨çš„ï¼Œæ‰€è°“æ•°æ®é©±åŠ¨ï¼Œè¿™æ„å‘³ç€å½“æˆ‘ä»¬æƒ³è¦å†™ä¸€ä¸ªç”¨äºè¯†åˆ«æ‰‹å†™æ•°å­—çš„æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å…³æ³¨çš„ä¸æ˜¯æŸä¸ªæ•°å­—å½¢çŠ¶ä¸Šæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Œå¦‚ä½•é€šè¿‡ç¼–ç¨‹è¯†åˆ«è¯¥ç‰¹ç‚¹ï¼Œè€Œæ˜¯ç›´æ¥å°†æ•°æ®é›†å–‚ç»™æ¨¡å‹ï¼Œæ¨¡å‹è‡ªåŠ¨è®­ç»ƒå¹¶è¯†åˆ«æ•°å­—ç±»åˆ«ã€‚

æ·±åº¦å­¦ä¹ æ¨¡å‹ç”±ä¸‰éƒ¨åˆ†ç»„æˆï¼š

- å‡è¯´æ¨¡å‹ï¼šæ¨¡å‹çš„ç»“æ„ï¼ŒåŒ…æ‹¬ä¸€ç³»åˆ—å‚æ•°ï¼Œå…¶æè¿°äº†æ¨¡å‹ä»è¾“å…¥åˆ°è¾“å‡ºçš„æ˜ å°„å…³ç³»ï¼›
- æŸå¤±å‡½æ•°ï¼šæŒ‡å®šäº†å¯¹æ¨¡å‹çš„è¯„ä»·ï¼ŒæŸå¤±å‡½æ•°å€¼è¶Šå°ï¼Œè¯´æ˜è¯¥æ¨¡å‹åœ¨æŒ‡å®šä»»åŠ¡ä¸Šå®Œæˆå¾—æ›´å¥½ï¼›
- ä¼˜åŒ–æ–¹æ³•ï¼šç”¨äºå¯¹æ¨¡å‹ä¸­å‚æ•°è¿›è¡Œä¼˜åŒ–ï¼Œä½¿å¾—æŸå¤±å‡½æ•°æœ€å°çš„æ–¹æ³•ã€‚

## Softmax å›å½’

ä»¥ç»å…¸çš„ softmax å›å½’æ¨¡å‹ä¸ºä¾‹ï¼Œç®€å•å›é¡¾ä¸€ä¸‹ ML æ¨¡å‹ã€‚

è€ƒè™‘ä¸€ä¸ª k åˆ†ç±»ä»»åŠ¡ï¼Œå…¶ä¸­æ•°æ®é›†ä¸º $x^{(i)} \in R^n\ ,\  y^{(i)} \in \{ 1,...,k\}\   \ \  i = 1,...,m$ï¼Œ$n$ æ ‡è¯†è¾“å…¥æ•°æ®é›†çš„ç»´åº¦ï¼Œ$k$ æ ‡è¯†æ ‡ç­¾ç±»åˆ«æ•°ï¼Œ$m$ æ ‡è¯†æ•°æ®é›†æ ·æœ¬æ•°é‡ã€‚

ä¸€ä¸ªå‡è¯´æ¨¡å‹å°±æ˜¯å°†ä¸€ä¸ª $n$ ç»´çš„è¾“å…¥æ˜ å°„åˆ°ä¸€ä¸ª $k$ ç»´çš„è¾“å‡ºï¼Œå³ï¼š$h: R^n \rightarrow R^k$ã€‚æ³¨æ„ï¼Œæ¨¡å‹å¹¶ä¸ä¼šç›´æ¥è¾“å‡ºç±»åˆ«çš„åºå·ï¼Œè€Œæ˜¯é€šè¿‡è¾“å‡ºä¸€ä¸ª $k$ ç»´å‘é‡ $h(x)$ï¼Œå…¶ä¸­ç¬¬ $i$ ä¸ªå…ƒç´  $h_i(x)$ è¡¨ç¤ºæ˜¯ç¬¬ $i$ ä¸ªç±»åˆ«çš„æ¦‚ç‡ã€‚

å¯¹äºçº¿æ€§æ¨¡å‹æ¥è¯´ï¼Œä½¿ç”¨ $\theta \in R^{n\times k}$ è¿™ä¸ªæ¨¡å‹ä¸­çš„å‚æ•°ï¼Œé‚£ä¹ˆ $h_\theta(x) = \theta^T x$ã€‚

å¦‚æœä¸€æ¬¡è¾“å…¥å¤šä¸ªæ•°æ®ï¼Œé‚£ä¹ˆè¾“å…¥æ•°æ®å°±å¯ä»¥ç»„ç»‡æˆä¸€ä¸ªçŸ©é˜µï¼Œç›¸æ¯”èµ·å¤šä¸ªå‘é‡æ“ä½œï¼ŒçŸ©é˜µçš„æ“ä½œé€šå¸¸æ•ˆç‡æ›´é«˜ï¼Œæˆ‘ä»¬åœ¨ä»£ç å®ç°ä¸­ä¸€èˆ¬ä¹Ÿæ˜¯ç”¨çŸ©é˜µæ“ä½œã€‚æ•°æ®é›†å¯ä»¥è¡¨ç¤ºä¸ºï¼š

{{< math_block >}}
X\in R^{m\times n}=\left[ \begin{array}{c}
	x^{(1)T}\\
	\vdots\\
	x^{\left( m \right) T}\\
\end{array} \right] ,  y\in \left\{ 1,...,k \right\} ^m=\left[ \begin{array}{c}
	y^{\left( 1 \right)}\\
	\vdots\\
	y^{\left( m \right)}\\
\end{array} \right]
{{< /math_block >}}

æ•°æ®é›†çš„çŸ©é˜µæ˜¯ä¸€ä¸ªä¸ªæ ·æœ¬è½¬ç½®åå †å  stack èµ·æ¥çš„ã€‚é‚£ä¹ˆè¾“å‡ºå¯ä»¥è¡¨ç¤ºä¸ºï¼š

{{< math_block >}}
h_{\theta}\left( X \right) =\left[ \begin{array}{c}
	h_{\theta}\left( x^{\left( 1 \right)} \right) ^T\\
	\vdots\\
	h_{\theta}\left( x^{\left( m \right)} \right) ^T\\
\end{array} \right] =\left[ \begin{array}{c}
	x^{\left( 1 \right) T}\theta\\
	\vdots\\
	x^{\left( m \right) T}\theta\\
\end{array} \right] =X\theta
{{< /math_block >}}

å…³äºæŸå¤±å‡½æ•° $l_{err}$ï¼Œä¸€ç§æœ´ç´ çš„æƒ³æ³•æ˜¯å°†æ¨¡å‹é¢„æµ‹é”™è¯¯çš„æ¨¡å‹æ•°æ®é‡ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œå³å¦‚æœæ¨¡å‹é¢„æµ‹çš„æ­£ç¡®ç‡æœ€é«˜çš„é‚£ä¸ªç±»åˆ«ä¸çœŸå®ç±»åˆ«ä¸ç›¸åŒï¼Œåˆ™æŸå¤±å‡½æ•°ä¸º 1ï¼Œå¦åˆ™ä¸º 0ï¼š

{{< math_block >}}
l_{err}\left( h\left( x \right) , y \right) \,\,=\,\,\left\{ \begin{align*}
	0 \ &\mathrm{if} \ \mathrm{argmax} _i\,\,h_i\left( x \right) =y\\
	1 \ &\mathrm{otherwise}\\
\end{align*} \right.
{{< /math_block >}}

é—æ†¾çš„æ˜¯ï¼Œè¿™ä¸ªç¬¦åˆç›´è§‰å‡½æ•°æ˜¯ä¸å¯å¾®åˆ†çš„ï¼Œéš¾ä»¥å¯¹å‚æ•°è¿›è¡Œä¼˜åŒ–ã€‚æ›´åˆé€‚çš„åšæ³•æ˜¯ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ã€‚

åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬å°†å…ˆè®²è¾“å‡ºè¿‡ä¸€ä¸ª softmax å‡½æ•°ï¼Œä½¿ä¹‹çš„è¡Œä¸ºæ›´åƒä¸€ä¸ªæ¦‚ç‡â€”â€”å„ä¸ªç±»åˆ«çš„æ¦‚ç‡ä¹‹å’Œä¸º 1ï¼š

{{< math_block >}}
z_i=p\left( \mathrm{label}=i \right) =\frac{\exp \left( h_i\left( x \right) \right)}{\sum_{j=1}^k{\exp \left( h_j\left( x \right) \right)}}
{{< /math_block >}}

é‚£ä¹ˆäº¤å‰ç†µæŸå¤±å‡½æ•°å°±å¯ä»¥å®šä¹‰ä¸ºï¼š

{{< math_block >}}
l_{ce}\left( h\left( x \right) ,y \right) =-\log p\left( \mathrm{label}=y \right) =-h_y\left( x \right) +\log \sum_{j=1}^k{\exp \left( h_j\left( x \right) \right)}
{{< /math_block >}}

æ³¨æ„åœ¨è®¡ç®—äº¤å‰ç†µæ—¶ï¼Œé€šè¿‡è¿ç®—è¿›è¡Œäº†åŒ–ç®€ï¼Œè¿™ä½¿å¾—æˆ‘ä»¬å¯ä»¥çœå»è®¡ç®— softmax çš„è¿‡ç¨‹ï¼Œç›´æ¥è®¡ç®—æœ€ç»ˆçš„ç»“æœã€‚ä¸ä½†å¦‚æ­¤ï¼Œäº¤å‰ç†µçš„è®¡ç®—ä¸­ï¼Œå¦‚æœ $h_i(x)$ çš„å€¼å¾ˆå°ï¼Œé‚£ä¹ˆå–å¯¹æ•°ä¼šå‡ºç°å¾ˆå¤§çš„å€¼ï¼ŒåŒ–ç®€åçš„è®¡ç®—åˆ™é¿å…äº†è¿™ç§æƒ…å†µã€‚

æ‰€æœ‰çš„æ·±åº¦å­¦ä¹ é—®é¢˜ï¼Œéƒ½å¯ä»¥å½’ç»“ä¸ºä¸€ä¸‹è¿™ä¸ªæœ€ä¼˜åŒ–é—®é¢˜ï¼š{{< math_block >}}
\mathop {\mathrm{minimize}} \limits_{\theta}\ \ \frac{1}{m}\sum_{i=1}^m{l(h_{\theta}(x^{(i)}),y^{(i)}))}
{{< /math_block >}}
æˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•å¯¹è¯¥é—®é¢˜è¿›è¡Œä¼˜åŒ–ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œé¦–å…ˆä»‹ç»ä¸€ä¸‹å…³äºæ¢¯åº¦ã€‚æˆ‘ä»¬çš„ä¼˜åŒ–ç›®æ ‡å¯ä»¥çœ‹ä½œä¸€ä¸ªå…³äº$\theta \in R^{n\times k}$çš„å‡½æ•°$f$ï¼Œé‚£ä¹ˆå…¶åœ¨$\theta_0$å¤„çš„æ¢¯åº¦å¯ä»¥è¡¨ç¤ºä¸ºï¼š
{{< math_block >}}
\nabla _{\theta}f\left( \theta _0 \right) \in R^{n\times k}=\left[ \begin{matrix}  
	\frac{\partial f\left( \theta _0 \right)}{\partial \theta _{11}}&		\cdots&		\frac{\partial f\left( \theta _0 \right)}{\partial \theta _{k1}}\\  
	\vdots&		\ddots&		\vdots\\  
	\frac{\partial f\left( \theta _0 \right)}{\partial \theta _{n1}}&		\cdots&		\frac{\partial f\left( \theta _0 \right)}{\partial \theta _{nk}}\\  
\end{matrix} \right]
{{< /math_block >}}
å…¶ä¸­ï¼Œç¬¬$i$è¡Œç¬¬$j$ä¸ªå…ƒç´ è¡¨ç¤ºé™¤$\theta_{ij}$ä¹‹å¤–çš„å‚æ•°éƒ½è¢«å½“ä½œå¸¸æ•°ï¼Œå¯¹$\theta_{ij}$æ±‚åå¯¼ã€‚

æ¢¯åº¦ä¸‹é™ï¼Œå°±æ˜¯æ²¿ç€æ¢¯åº¦æ–¹å‘ä¸æ–­è¿›è¡Œè¿­ä»£ï¼Œä»¥æ±‚æ‰¾åˆ°æœ€ä½³çš„$\theta$ä½¿å¾—ç›®æ ‡å‡½æ•°å€¼æœ€å°ã€‚
{{< math_block >}}
\theta :=\theta _0-\alpha \nabla f\left( \theta _0 \right)
{{< /math_block >}}
ä¸Šå¼ä¸­ï¼Œ$\alpha$è¢«ç§°ä¸ºå­¦ä¹ ç‡æˆ–è€…æ­¥é•¿ã€‚

äº‹å®ä¸Šï¼Œåœ¨ç°ä»£æ·±åº¦å­¦ä¹ ä¸­ï¼Œå¹¶ä¸æ˜¯ä½¿ç”¨çš„ä¼ ç»Ÿæ¢¯åº¦ä¸‹é™çš„æ–¹æ¡ˆï¼Œå› ä¸ºå…¶æ— æ³•å°†æ‰€æœ‰è®­ç»ƒé›†ä¸€æ¬¡æ€§è¯»å…¥å¹¶è®¡ç®—æ¢¯åº¦ã€‚ç°ä»£ä½¿ç”¨çš„æ˜¯éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆStochastic Gradient Descentï¼ŒSGDï¼‰

é¦–å…ˆå°†mä¸ªè®­ç»ƒé›†æ ·æœ¬åˆ’åˆ†ä¸€ä¸ªä¸ªå°batchï¼Œæ¯ä¸ªbatchéƒ½æœ‰Bæ¡æ•°æ®ã€‚é‚£æ¯ä¸€batchçš„æ•°æ®è¡¨ç¤ºä¸º$X\in R^{B\times n}$ï¼Œæ›´æ–°å‚æ•°$\theta$çš„å…¬å¼å˜ä¸ºï¼š
{{< math_block >}}
\theta :=\theta _0-\frac{\alpha}{B}\nabla f\left( \theta _0 \right)
{{< /math_block >}}
æˆ‘ä»¬çš„æ¢¯åº¦å˜æˆäº†æ¯ä¸ªå°batchå¯¹å…¨ä½“æ ·æœ¬æ¢¯åº¦çš„ä¼°è®¡ã€‚

é‚£å¦‚ä½•è®¡ç®—æ¢¯åº¦è¡¨è¾¾å¼å‘¢ï¼Ÿæ¢¯åº¦çŸ©é˜µä¸­æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªåå¯¼æ•°ï¼Œæˆ‘ä»¬å°±å…ˆä»è®¡ç®—åå¯¼æ•°å¼€å§‹ã€‚å‡è®¾$h$æ˜¯ä¸ªå‘é‡ï¼Œæˆ‘ä»¬æ¥è®¡ç®—åå¯¼æ•°$\frac{\partial l_{ce}\left( h,y \right)}{\partial h_i}$ï¼š
{{< math_block >}}
\begin{align*}  
\frac{\partial l_{ce}\left( h,y \right)}{\partial h_i}&=\frac{\partial}{\partial h_i}\left( -h_y+\log \sum_{j=1}^k{\exp h_j} \right)  
\\  
&=-1\left\{ i=y \right\} +\frac{\exp \left( h_j \right)}{\sum_{j=1}^k{\exp h_j}}  
\\  
&=-1\left\{ i=y \right\} +\mathrm{softmax} \left( h \right)  
\\  
&=z-e_y  
\end{align*}
{{< /math_block >}}

å¦‚æœ$h$æ˜¯ä¸ªå‘é‡ï¼Œé‚£ä¹ˆæ¢¯åº¦$\nabla_h l_{ce}(h,y)$å°±èƒ½å¤Ÿä»¥å‘é‡çš„å½¢å¼è¡¨ç¤ºä¸ºï¼š
{{< math_block >}}
\nabla_h l_{ce}(h,y) = z-e_y
{{< /math_block >}}
è¿™é‡Œæˆ‘ä»¬å°†å¯¹$h$è¿›è¡Œsoftmaxæ ‡å‡†åŒ–è®°ä¸º$z$ï¼Œ$e_y$è¡¨ç¤ºå¯¹åº”çš„å•ä½å‘é‡ã€‚

äº‹å®ä¸Šï¼Œæˆ‘ä»¬è¦è®¡ç®—çš„æ¢¯åº¦æ˜¯å…³äº$\theta$çš„ï¼Œå…·ä½“æ¥è¯´ï¼Œè¡¨è¾¾å¼ä¸º$\nabla_\theta l_{ce}(\theta^Tx,y)$ï¼Œå…¶ä¸­ï¼Œ$\theta$æ˜¯ä¸ªçŸ©é˜µã€‚æˆ–è®¸ï¼Œå¯ä»¥ä½¿ç”¨é“¾å¼æ³•åˆ™è¿›è¡Œæ±‚è§£ï¼Œä½†æ˜¯å¤ªéº»çƒ¦äº†ï¼Œè¿™é‡Œè¿˜æ¶‰åŠçŸ©é˜µå¯¹å‘é‡çš„æ±‚å¯¼ã€‚æˆ‘ä»¬éœ€è¦ä¸€ç§æ›´åŠ é€šç”¨çš„æ±‚å¯¼æ–¹æ¡ˆã€‚

æœ‰ä¸¤ä¸ªè§£å†³åŠæ³•ï¼š
- æ­£ç¡®ä¸”å®˜æ–¹çš„åšæ³•ï¼šä½¿ç”¨çŸ©é˜µå¾®åˆ†å­¦ã€é›…å¯æ¯”çŸ©é˜µã€å…‹ç½—å†…å…‹ç§¯å’Œå‘é‡åŒ–ç­‰çŸ¥è¯†è¿›è¡Œæ±‚è§£ã€‚
- ä¸€ä¸ªhackyã€ç™»ä¸ä¸Šå°é¢ã€ä½†å¤§å®¶éƒ½åœ¨ç”¨çš„æ–¹æ¡ˆï¼šå°†æ‰€æœ‰çš„çŸ©é˜µå’Œå‘é‡å½“ä½œæ ‡é‡ï¼Œä½¿ç”¨é“¾å¼æ³•åˆ™æ±‚è§£ï¼Œå¹¶è¿›è¡Œè½¬ç½®æ“ä½œä½¿å¾—ç»“æœçš„sizeç¬¦åˆé¢„æœŸï¼Œæœ€åæ£€æŸ¥æ•°å€¼ä¸Šç»“æœæ˜¯å¦æ­£ç¡®ã€‚

æŒ‰ç…§ç¬¬äºŒä¸ªæ–¹æ³•çš„é€»è¾‘ï¼Œè¿‡ç¨‹ä¸ºï¼š
{{< math_block >}}
\begin{align*}  
\frac{\partial}{\partial \theta}l_{ce}\left( \theta ^Tx,y \right) &=\frac{\partial l_{ce}\left( \theta ^Tx,y \right)}{\partial \theta ^Tx}\cdot \frac{\partial \theta ^Tx}{\partial \theta}  
\\  
&=\left[ z-e_y \right] _{k\times 1}\cdot x_{n\times 1}  
\\  
&=x\cdot \left[ z-e_y \right]  
\end{align*}
{{< /math_block >}}
å…¶ä¸­ï¼Œ$z=\text{softmax}(\theta^Tx)$ã€‚æ³¨æ„ï¼Œå€’æ•°ç¬¬äºŒæ­¥æ±‚å‡ºçš„ç»“æœæ˜¯ä¸¤ä¸ªåˆ—å‘é‡ç›¸ä¹˜ï¼Œä¸èƒ½è¿ç®—ã€‚åˆå·²çŸ¥ç»“æœåº”è¯¥æ˜¯$n\times k$çš„çŸ©é˜µï¼Œè°ƒæ•´å‘é‡ä¹‹é—´çš„é¡ºåºå³å¯ã€‚

ç…§çŒ«ç”»è™ï¼Œå¯ä»¥å†™å‡ºbatchçš„æƒ…å†µï¼Œ$X\in R^{B\times n}$ï¼š
{{< math_block >}}
\begin{align*}  
\frac{\partial}{\partial \theta}l_{ce}\left( \theta ^TX,y \right) &=\frac{\partial l_{ce}\left( \theta ^TX,y \right)}{\partial \theta ^TX}\cdot \frac{\partial \theta ^TX}{\partial \theta}  
\\  
&=\left[ Z-E_y \right] _{B\times k}\cdot X_{B\times n}  
\\  
&=X^T\cdot \left[ Z-E_y \right]  
\end{align*}
{{< /math_block >}}

# Lecture 3: Manual Neural Networks
è¿™èŠ‚è¯¾ï¼Œæˆ‘ä»¬å°†äººå·¥å®ç°å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼Œä¹‹åçš„è¯¾ç¨‹ï¼Œå°†å¼•å…¥è‡ªåŠ¨å¾®åˆ†æŠ€æœ¯ã€‚
## ä»çº¿æ€§æ¨¡å‹è½¬å˜ä¸ºéçº¿æ€§æ¨¡å‹
![image.png](https://pics.zhouxin.space/202406071816708.png?x-oss-process=image/quality,q_90/format,webp)

å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œçº¿æ€§æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯å°†æ ·æœ¬ç©ºé—´åˆ’åˆ†ä¸ºçº¿æ€§çš„å‡ ä¸ªéƒ¨åˆ†ï¼Œè¿™æ ·çš„æ¨¡å‹æ€§èƒ½ååˆ†æœ‰é™ï¼Œå› æ­¤å¾ˆå¤šä¸æ»¡è¶³è¿™æ ·åˆ†å¸ƒçš„å®é™…é—®é¢˜å°±ä¸èƒ½è¢«è§£å†³ã€‚

ä¸€ç§è§£å†³æ–¹æ¡ˆæ˜¯ï¼Œåœ¨å°†æ ·æœ¬è¾“å…¥åˆ°çº¿æ€§åˆ†ç±»å™¨å‰ï¼Œå…ˆäººå·¥æŒ‘é€‰å‡ºæŸäº›ç‰¹å¾ï¼Œå³å¯¹$X$åº”ç”¨ä¸€ä¸ªå‡½æ•°$\phi$ï¼Œå…¶å°†$X$æ˜ å°„åˆ°$\phi(X)$ä¸Šï¼Œæ˜ å°„åçš„ç©ºé—´å¯ä»¥è¢«çº¿æ€§åˆ’åˆ†ã€‚ä¸€æ–¹é¢ï¼Œå®ƒç¡®å®æ˜¯æ—©æœŸå®è·µä¸­è¡Œä¹‹æœ‰æ•ˆçš„æ–¹æ¡ˆï¼›å¦ä¸€æ–¹é¢ï¼Œäººå·¥æå–ç‰¹å¾çš„æ³›åŒ–æ€§èƒ½æœ‰é™ï¼Œå—é™äºå…·ä½“é—®é¢˜å’Œç ”ç©¶äººå‘˜çš„å¯¹é—®é¢˜çš„æ´å¯Ÿç¨‹åº¦ã€‚

å¦‚æœæˆ‘ä»¬ä½¿ç”¨çº¿æ€§ç½‘ç»œæå–ç‰¹å¾ï¼Œå¹¶ç›´æ¥æ¥ä¸Šä¸€ä¸ªçº¿æ€§åˆ†ç±»å¤´ï¼Œè¿™ä¸¤ä¸ªçº¿æ€§å±‚ç­‰æ•ˆä¸ºä¸€ä¸ªçº¿æ€§å±‚ï¼Œå¹¶ä¸èƒ½åšåˆ°éçº¿æ€§åŒ–çš„è¦æ±‚ï¼ˆåŸºç¡€çŸ¥è¯†ï¼Œæ­¤å¤„ä¸å†è§£é‡Šï¼‰ã€‚

å› æ­¤ï¼Œåœ¨ä½¿ç”¨çº¿æ€§ç½‘ç»œæå–ç‰¹å¾åï¼Œéœ€è¦å†æ¥ä¸Šä¸€ä¸ªéçº¿æ€§å‡½æ•°$\sigma$ï¼Œå³$\phi = \sigma (W^T X)$ã€‚
## ç¥ç»ç½‘ç»œ
ä¸Šæ–‡æåˆ°çš„ä½¿ç”¨éçº¿æ€§å‡½æ•°åçš„æ¨¡å‹ï¼Œå°±å¯ä»¥è§†ä½œä¸€ç§æœ€ç®€å•çš„ç¥ç»ç½‘ç»œã€‚æ‰€è°“ç¥ç»ç½‘ç»œï¼Œå€¼å¾—æ˜¯æœºå™¨å­¦ä¹ ä¸­æŸä¸€ç±»ç‰¹å®šçš„å‡è¯´æ¨¡å‹ï¼Œå…¶ç”±å¤šå±‚ç»„æˆï¼Œæ¯ä¸€å±‚éƒ½æœ‰å¤§é‡å¯ä»¥å¾®åˆ†çš„å‚æ•°ã€‚

ç¥ç»ç½‘ç»œæœ€åˆçš„ç¡®èµ·æºäºæ¨¡æ‹Ÿäººç±»ç¥ç»å…ƒè¿™ä¸€åŠ¨æœºï¼Œä½†éšç€å…¶å‘å±•ï¼Œè¶Šæ¥è¶Šå¤šçš„ç¥ç»ç½‘ç»œæ¨¡å‹å‡ºç°ï¼Œä¸äººç±»å¤§è„‘ç¥ç»ç½‘ç»œè¶Šæ¥è¶Šä¸ç›¸å…³ã€‚

ä»¥åŒå±‚ç¥ç»ç½‘ç»œä¸ºä¾‹ï¼Œå…¶å½¢å¼åŒ–è¡¨ç¤ºä¸º$h_\theta(x) = W_2^T \sigma(W_1^T x)$ï¼Œæ‰€æœ‰å¯å­¦ä¹ çš„å‚æ•°ä½¿ç”¨$\theta$è¡¨ç¤ºã€‚ä»¥batchçš„çŸ©é˜µå½¢å¼è¡¨ç¤ºä¸ºï¼š
{{< math_block >}}
h_\theta(X) = \sigma(XW_1)W_2
{{< /math_block >}}
æ¥ä¸‹æ¥ç»™å‡ºLå±‚å¤šå±‚æ„ŸçŸ¥æœºï¼ˆa.k.a. MLPã€å‰é¦ˆç¥ç»ç½‘ç»œã€å…¨è¿æ¥å±‚ï¼‰çš„å½¢å¼åŒ–è¡¨è¾¾ï¼š
{{< math_block >}}
\left\{\begin{array}{l}  
Z_{i+1} = \sigma_i(Z_iW_i), i=1,...,L  \\  
Z_1 = X\\  
h_\theta(X) =Z_{L+1}\\  
[Z_i\in R^{m\times n_i}, W_i \in R^{n_i\times n_{i+1}}]\\  
\sigma_i:R\rightarrow R

\end{array} \right.
{{< /math_block >}}
æ¯ä¸€å±‚çš„è¾“å…¥ä¸º$Z_i$ï¼Œè¾“å‡ºä¸º$Z_{i+1}$ã€‚

ä¸ºä»€ä¹ˆè¦æ˜¯ç”¨æ·±åº¦ç½‘ç»œè€Œä¸æ˜¯å®½åº¦ç½‘ç»œï¼Ÿæ²¡æœ‰å¾ˆå®Œç¾çš„è§£é‡Šï¼Œä½†æœ€å¥½å¹¶ä¸”æœ€ç°å®çš„è§£é‡Šæ˜¯ï¼šç»éªŒè¯æ˜ï¼Œå½“å‚æ•°é‡å›ºå®šæ—¶ï¼Œæ·±åº¦ç½‘ç»œæ€§èƒ½ä¼˜äºå®½åº¦ç½‘ç»œã€‚
## åå‘ä¼ æ’­ï¼ˆæ¢¯åº¦è®¡ç®—ï¼‰
ä¸Lecture 2ä¸€è‡´ï¼Œä½¿ç”¨äº¤å‰ç†µä½œä¸ºæŸå¤±å‡½æ•°ï¼Œä½¿ç”¨SGDä½œä¸ºä¼˜åŒ–ç®—æ³•ï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯ï¼Œè¿™æ¬¡è¦å¯¹MLPç½‘ç»œæ±‚è§£æ¢¯åº¦ã€‚

å¯¹äºä¸¤å±‚ç¥ç»ç½‘ç»œ$h_\theta(X) = \sigma(XW_1)W_2$ï¼Œå¾…æ±‚çš„æ¢¯åº¦è¡¨è¾¾å¼ä¸ºï¼š
{{< math_block >}}
\nabla_{\{W_1, W_2\}}l_{ce}(\sigma(XW_1)W_2,y)
{{< /math_block >}}
å¯¹äº$W_2$çš„æ¢¯åº¦ï¼Œå…¶ä¸Lecture 2çš„è®¡ç®—ç±»ä¼¼ï¼š
{{< math_block >}}
\begin{align*}  
\frac{\partial l_{ce}(\sigma(XW_1)W_2,y)}{\partial W_2}&=\frac{\partial l_{ce}(\sigma(XW_1)W_2,y)}{\partial \sigma(XW_1)W_2} \cdot \frac{\partial\sigma(XW_1)W_2}{\partial W_2}\\  
&=(S-I_y)_{m\times k}\cdot \sigma(XW_1)_{m\times d}\\  
&=\sigma(XW_1)^T\cdot (S-I_y)\\  
&[S=\text{softmax}(\sigma(XW_1))]  
\end{align*}
{{< /math_block >}}

å¯¹äº$W_1$çš„æ¢¯åº¦ï¼Œå…¶éœ€è¦å¤šæ¬¡åº”ç”¨é“¾å¼æ³•åˆ™ï¼Œä½†å¹¶ä¸éš¾è®¡ç®—ï¼š
{{< math_block >}}
\begin{align*}  
\frac{\partial l_{ce}(\sigma(XW_1)W_2,y)}{\partial W_1}&=\frac{\partial l_{ce}(\sigma(XW_1)W_2,y)}{\partial \sigma(XW_1)W_2} \cdot \frac{\partial\sigma(XW_1)W_2}{\partial \sigma(XW_1)}\cdot \frac{\partial \sigma(XW_1)}{\partial XW_1}\cdot\frac{\partial XW_1}{\partial X_1}\\  
&=(S-I_y)_{m\times k}\cdot [W_2]_{d\times k}\cdot \sigma\prime(XW_1)_{m\times d}\cdot X_{m\times n}\\  
&=X^T\cdot [\sigma\prime(XW_1)\odot((S-I_y)\cdot W_2^T)]\\  
&[S=\text{softmax}(\sigma(XW_1))]  
\end{align*}
{{< /math_block >}}
ä»¥ä¸Šå…¬å¼ä¸­$\odot$è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•ã€‚è‡³äºä¸ºå•¥è¿™ä¹ˆç®—ï¼Œä¿ºä¹Ÿä¸çŸ¥é“ã€‚

æ¥ä¸‹æ¥å°†å…¶æ¨å¹¿åˆ°ä¸€èˆ¬æƒ…å†µï¼Œå³$L$å±‚çš„MLPä¸­å¯¹$W_i$æ±‚å¯¼ï¼š
{{< math_block >}}
\begin{align*}  
\frac{\partial l(Z_{l+1},y)}{\partial W_i} &=\frac{\partial l}{\partial Z_{l+1}}\cdot \frac{\partial Z_{l+1}}{\partial Z_{l}}\cdot...\cdot \frac{\partial Z_{i+2}}{\partial Z_{i+1}}\cdot\frac{\partial Z_{i+1}}{\partial W_{i}}\\  
&=G_{i+1}\cdot\frac{\partial Z_{i+1}}{\partial W_{i}}=\frac{\partial l}{\partial Z_{i+1}}\cdot \frac{\partial Z_{i+1}}{W_i}\\

\end{align*}
{{< /math_block >}}

ç”±ä¸Šè¿°å…¬å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ä¸ªåå‘è¿­ä»£è®¡ç®—çš„$G_i$ï¼Œå³ï¼š
{{< math_block >}}
\begin{align*}  
G_i &= G_{i+1}\cdot \frac{Z_{i+1}}{Z_i} \\  
&=G_{i+1}\cdot \frac{\partial \sigma(Z_iW_i)}{\partial Z_iW_i}\cdot\frac{\partial Z_iW_i}{Z_i}\\  
&=G_{i+1}\cdot \sigma\prime(Z_iW_i)\cdot W_i\\  
\end{align*}
{{< /math_block >}}

ä¸Šé¢çš„è®¡ç®—éƒ½æ˜¯å°†çŸ©é˜µå½“ä½œæ ‡é‡è¿›è¡Œçš„ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬è€ƒè™‘å…¶ç»´åº¦ã€‚å·²çŸ¥ï¼Œ$Z_i \in R^{m\times n_i}$æ˜¯ç¬¬$i$å±‚çš„è¾“å…¥ï¼Œ$G_i = \frac{\partial l}{\partial Z_{i}}$ï¼Œå…¶ç»´åº¦å¦‚ä½•å‘¢ï¼Ÿ$G_i$æ¯ä¸ªå…ƒç´ è¡¨ç¤ºæŸå¤±å‡½æ•°$l$å¯¹ç¬¬$i$å±‚è¾“å…¥çš„æ¯ä¸€é¡¹æ±‚åå¯¼ï¼Œä¹Ÿå¯ä»¥è®°ä½œæ˜¯$l$å¯¹$Z_i$æ±‚æ¢¯åº¦ï¼Œå³$\nabla_{Z_i} l$ï¼Œå…¶ç»´åº¦æ˜¾ç„¶æ˜¯$m\times n_i$ï¼Œç»§ç»­è®¡ç®—å‰æ–‡$G_i$ï¼š
{{< math_block >}}
\begin{align*}  
G_i &=[G_{i+1}]_{m\times n_{i+1}}\cdot \sigma\prime(Z_iW_i)_{m\times n_{i+1}}\cdot [W_i]_{n_i\times n_{i+1}}\\  
&= [G_{i+1}\odot \sigma\prime(Z_iW_i)]W_i^T  
\end{align*}
{{< /math_block >}}

æœ‰äº†$G_i$ï¼Œå°±å¯ä»¥ç»§ç»­è®¡ç®—$l$å¯¹$W_i$çš„åå¯¼æ•°äº†ï¼š
{{< math_block >}}
\begin{align*}  
\frac{\partial l(Z_{l+1},y)}{\partial W_i} &=G_{i+1}\cdot\frac{\partial Z_{i+1}}{\partial W_{i}} \\  
&=G_{i+1}\cdot \frac{\partial\sigma(Z_iW_i)}{\partial Z_iW_i}\cdot\frac{\partial Z_iW_i}{\partial W_i}\\  
&=[G_{i+1}]_{m\times n_{i+1}}\cdot \sigma\prime(Z_iW_i)_{m\times n_{i+1}}\cdot [Z_i]_{m\times n_i}\\  
&=Z_i^T\cdot[G_{i+1}\odot\sigma\prime(Z_iW_i)]  
\end{align*}
{{< /math_block >}}

è‡³æ­¤ï¼Œæ¯ä¸ªå°ç»„ä»¶éƒ½å·²åˆ¶é€ å®Œæ¯•ï¼Œè®©æˆ‘ä»¬æ¥æŠŠå®ƒè£…èµ·æ¥å§ï¼
- å‰å‘ä¼ æ’­
	- åˆå§‹åŒ–ï¼š$Z_1 = X$
	- è¿­ä»£ï¼š$Z_{i+1} = \sigma(Z_iW_i)$ ç›´è‡³$i=L$ï¼ˆæ³¨æ„ï¼Œæœ€åä¸€å±‚æ²¡æœ‰éçº¿æ€§éƒ¨åˆ†ï¼Œæ­¤å¤„æ²¡æœ‰å±•ç¤ºå‡ºæ¥ï¼‰
- åå‘ä¼ æ’­
	- åˆå§‹åŒ–ï¼š$G_{L+1} = S-I_y$
	- è¿­ä»£ï¼š$G_i=[G_{i+1}\odot \sigma\prime(Z_iW_i)]W_i^T$ ç›´è‡³$i=1$
å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨åå‘ä¼ æ’­ä¸­ï¼Œéœ€è¦ç”¨åˆ°å‰å‘ä¼ æ’­çš„ä¸­é—´ç»“æœ$Z_i$ã€‚ä¸ºäº†æ›´é«˜æ•ˆåœ°è®¡ç®—æ¢¯åº¦ï¼Œä¸å¾—ä¸ä»¥ç‰ºç‰²å†…å­˜ç©ºé—´ä¸ºä»£ä»·ï¼Œå³ç©ºé—´æ¢æ—¶é—´ã€‚

> è®¸å¤šè¯¾ç¨‹ï¼Œè®²åˆ°è¿™é‡Œå°±ç»“æŸäº†ï¼Œä½†å¯¹æˆ‘ä»¬è¿™é—¨è¯¾æ¥è¯´ï¼Œæ‰åˆšåˆšå¼€å§‹...

# Lecture 4: Automatic Differentiation
## åŸºæœ¬å·¥å…·
- è®¡ç®—å›¾
è®¡ç®—å›¾æ˜¯è‡ªåŠ¨å¾®åˆ†ä¸­å¸¸ç”¨çš„ä¸€ç§å·¥å…·ã€‚è®¡ç®—å›¾æ˜¯ä¸€å¼ æœ‰å‘æ— ç¯å›¾ï¼Œæ¯ä¸ªèŠ‚ç‚¹è¡¨ç¤ºï¼ˆä¸­é—´ç»“æœï¼‰å€¼ï¼Œæ¯æ¡è¾¹è¡¨ç¤ºè¾“å…¥è¾“å‡ºå˜é‡ã€‚ä¾‹å¦‚ï¼Œ$y=f(x_1, x_2) = \ln(x_1)+x_1x_2-\sin x_2$å¯¹åº”çš„è®¡ç®—å›¾ä¸ºï¼š
![](https://pics.zhouxin.space/202406071612073.webp?x-oss-process=image/quality,q_90/format,webp)
æŒ‰ç…§æ‹“æ‰‘åºåˆ—éå†è¿™å¼ å›¾ï¼Œå°±å¯ä»¥å¾—åˆ°å¯¹åº”è¡¨è¾¾å¼çš„å€¼ã€‚
## å¯¹è‡ªåŠ¨å¾®åˆ†æ–¹æ³•çš„ç®€å•ä»‹ç»
æ·±åº¦å­¦ä¹ ä¸­ï¼Œä¸€ä¸ªæ ¸å¿ƒå†…å®¹å°±æ˜¯è®¡ç®—æ¢¯åº¦ã€‚è¿™é‡Œä»‹ç»é›†ä¸­è®¡ç®—æ¢¯åº¦çš„æ–¹æ¡ˆï¼š
- åå¯¼æ•°å®šä¹‰
- 
æ¢¯åº¦æ˜¯ç”±ä¸€ä¸ªä¸ªåå¯¼æ•°ç»„æˆçš„ï¼Œå¯ä»¥ç›´æ¥æ ¹æ®åå¯¼æ•°çš„å®šä¹‰æ¥è®¡ç®—æ¢¯åº¦ï¼š
{{< math_block >}}
\frac{\partial f(\theta)}{\partial \theta_i} = \lim_{\epsilon \to 0}\frac{f(\theta + \epsilon e_i) - f(\theta)}{\epsilon}
{{< /math_block >}}
å…¶ä¸­ï¼Œ$e_i$æ˜¯è¡¨ç¤ºç¬¬$i$ä¸ªæ–¹å‘ä¸Šçš„å•ä½å‘é‡ã€‚

- æ•°å€¼æ±‚è§£
æ ¹æ®ä¸Šè¿°å®šä¹‰ï¼Œæˆ‘ä»¬å¯ä»¥é€‰å–ä¸€ä¸ªå¾ˆå°çš„é‡ä»£å…¥$\epsilon$ï¼Œå¾—åˆ°æ•°å€¼è®¡ç®—åå¯¼çš„æ–¹æ³•ï¼š
{{< math_block >}}
\frac{\partial f(\theta)}{\partial \theta_i} = \frac{f(\theta + \epsilon e_i) - f(\theta - \epsilon e_i)}{2\epsilon} + o(\epsilon^2)
{{< /math_block >}}
è¿™é‡Œå¹¶ä¸æ˜¯ç›´æ¥ä½¿ç”¨ç¬¬ä¸€é¡¹çš„å…¬å¼ï¼Œå³åˆ†å­ä¸æ˜¯$f(\theta + \epsilon e_i) - f(\theta)$ï¼Œå¹¶ä¸”è¯¯å·®é¡¹æ˜¯$\epsilon^2$ï¼Œè¿™æ˜¯ç”±äºæ³°å‹’å±•å¼€ï¼š
{{< math_block >}}
\begin{align*}  
f(\theta+\delta) = f(\theta)+f^\prime (\theta)\delta+\frac{1}{2}f^{\prime \prime}(\theta)\delta^2+o(\delta^3)\\  
f(\theta-\delta) = f(\theta)+f^\prime (\theta)\delta-\frac{1}{2}f^{\prime \prime}(\theta)\delta^2+o(\delta^3)  
\end{align*}
{{< /math_block >}}
ä¸Šè¿°ä¸¤å¼ä½œå·®ï¼Œå³å¯å¾—åˆ°æ•°å€¼è®¡ç®—$f^\prime(\theta)$çš„æ–¹æ³•ã€‚

è¿™ä¸ªæ–¹æ³•çš„é—®é¢˜åœ¨äºå­˜åœ¨è¯¯å·®ï¼Œå¹¶ä¸”æ•ˆç‡ä½ä¸‹ï¼ˆè¿™é‡Œè¦è®¡ç®—ä¸¤æ¬¡fï¼‰ï¼Œè¯¥æ–¹æ³•å¸¸ç”¨äºéªŒè¯å…¶å®ƒæ–¹æ³•çš„å…·ä½“å®ç°æ˜¯å¦å‡ºé”™ã€‚å…·ä½“æ¥è¯´ï¼ŒéªŒè¯å¦‚ä¸‹ç­‰å¼æ˜¯å¦æˆç«‹ï¼š
{{< math_block >}}
\delta^T \nabla_\theta f(\theta) = \frac{f(\theta + \epsilon \delta) - f(\theta - \epsilon \delta)}{2 \epsilon} + o(\epsilon^2)
{{< /math_block >}}
å…¶ä¸­$\delta$æ˜¯å•ä½çƒä¸Šçš„æŸä¸ªå‘é‡ï¼Œ$\nabla_\theta f(\theta)$æ˜¯ä½¿ç”¨å…¶å®ƒæ–¹æ³•è®¡ç®—å¾—åˆ°çš„æ¢¯åº¦ã€‚ç­‰å¼å·¦è¾¹æ˜¯å…¶å®ƒæ–¹æ³•è®¡ç®—çš„æ¢¯åº¦åœ¨$\delta$ä¸Šçš„æŠ•å½±ï¼Œå³ä¾§æ˜¯ä½¿ç”¨æ•°å€¼æ±‚è§£å¾—åˆ°çš„æ¢¯åº¦å€¼ï¼ŒéªŒè¯è¯¥ç­‰å¼æ˜¯å¦æˆç«‹å°±å¯ä»¥åˆ¤æ–­å·¦ä¾§æ¢¯åº¦æ˜¯å¦è®¡ç®—é”™è¯¯ã€‚

- ç¬¦å·å¾®åˆ†
ç¬¦å·å¾®åˆ†ï¼Œå°±æ˜¯æ ¹æ®å¾®åˆ†çš„è®¡ç®—è§„åˆ™ä½¿ç”¨ç¬¦å·æ‰‹åŠ¨è®¡ç®—å¾®åˆ†ã€‚éƒ¨åˆ†è§„åˆ™ä¸ºï¼š
{{< math_block >}}
\begin{align*}  
&\frac{\partial (f(\theta) + g(\theta))}{\partial \theta} = \frac{\partial f(\theta)}{\partial \theta} + \frac{\partial g(\theta)}{\partial \theta}\\  
&\frac{\partial (f(\theta) g(\theta))}{\partial \theta} = g(\theta) \frac{\partial f(\theta)}{\partial \theta} + f(\theta) \frac{\partial g(\theta)}{\partial \theta}\\  
&\frac{\partial f(g(\theta))}{\partial\theta}=\frac{\partial f(g(\theta))}{\partial g(\theta)}\frac{\partial g(\theta)}{\partial\theta}  
\end{align*}
{{< /math_block >}}
æ ¹æ®è¯¥å…¬å¼ï¼Œå¯ä»¥è®¡ç®—å¾—åˆ°$f(\theta) = \prod_{i=1}^{n} \theta_i$çš„æ¢¯åº¦è¡¨è¾¾å¼ä¸ºï¼š$\frac{\partial f(\theta)}{\partial \theta_k} = \prod_{j \neq k}^{n} \theta_j$ã€‚å¦‚æœæˆ‘ä»¬æ ¹æ®è¯¥å…¬å¼æ¥è®¡ç®—æ¢¯åº¦ï¼Œä¼šå‘ç°éœ€è¦è®¡ç®—$n(n-2)$æ¬¡ä¹˜æ³•æ‰èƒ½å¾—åˆ°ç»“æœã€‚è¿™æ˜¯å› ä¸ºåœ¨ç¬¦å·è¿ç®—çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¿½ç•¥äº†å¯ä»¥åå¤åˆ©ç”¨çš„ä¸­é—´ç»“æœã€‚

- æ­£å‘æ¨¡å¼è‡ªåŠ¨å¾®åˆ† forward mode automatic differentiation
æ²¿ç€è®¡ç®—å›¾çš„æ‹“æ‰‘åºåˆ—ï¼ŒåŒæ ·å¯ä»¥è®¡ç®—å‡ºè¾“å‡ºå…³äºè¾“å…¥çš„å¯¼æ•°ï¼Œè¿˜æ˜¯ä»¥$y=f(x_1, x_2) = \ln(x_1)+x_1x_2-\sin x_2$ä¸ºä¾‹ï¼Œå…¶è®¡ç®—å›¾ä¸ºï¼š
![image.png](https://pics.zhouxin.space/202406071612328.png?x-oss-process=image/quality,q_90/format,webp)


æ•´ä¸ªæ¢¯åº¦è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹ï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­åº”ç”¨åˆ°äº†å…·ä½“å‡½æ•°çš„æ±‚å¯¼å…¬å¼ï¼š
{{< math_block >}}
\begin{align*}  
&\dot\nu_{1} =1 \\  
&\dot\nu_{2} =0 \\  
&\dot{\nu}_{3} =v_{1}/v_{1}=0.5 \\  
&\dot{\nu}_{4} =\hat{v}_{1}v_{2}+v_{2}v_{1}=1\times5+0\times2=5 \\  
&\dot\nu_{5} =\dot{v_{2}}\cos v_{2}=0\times\cos5=0 \\  
&\dot{\nu}_{6} =v_{3}+v_{4}=0.5+5=5.5 \\  
&\dot{\nu}_{7} =\dot{v_{6}}-\dot{v_{5}}=5.5-0=5.5  
\end{align*}
{{< /math_block >}}

å¯¹äº$f:\mathbb{R}^n \to \mathbb{R}^k$ï¼Œå‰å‘ä¼ æ’­éœ€è¦$n$æ¬¡å‰å‘è®¡ç®—æ‰èƒ½å¾—åˆ°å…³äºæ¯ä¸ªè¾“å…¥çš„æ¢¯åº¦ï¼Œè¿™å°±æ„å‘³å‰å‘ä¼ æ’­é€‚åˆ$n$æ¯”è¾ƒå°ã€$k$æ¯”è¾ƒå¤§çš„æƒ…å†µã€‚ä½†æ˜¯åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œé€šå¸¸$n$æ¯”è¾ƒå¤§ã€$k$æ¯”è¾ƒå°ã€‚

- åå‘æ¨¡å¼è‡ªåŠ¨å¾®åˆ†
å®šä¹‰$\text{adjoint}:\overline{v_i}=\frac{\partial y}{\partial v_i}$,å…¶è¡¨ç¤ºæŸå¤±å‡½æ•°å¯¹äºå‚æ•°$v_i$çš„åå¯¼ã€‚
æ•´ä¸ªè®¡ç®—è¿‡ç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼Œéœ€è¦æ³¨æ„çš„æ˜¯$\overline{v_2}$çš„è®¡ç®—è¿‡ç¨‹ï¼Œå…¶åœ¨è®¡ç®—å›¾ä¸Šå»¶ä¼¸å‡ºäº†ä¸¤ä¸ªèŠ‚ç‚¹ï¼Œå› æ­¤æ¢¯åº¦ä¹Ÿç”±ä¸¤éƒ¨åˆ†ç›¸åŠ ï¼š
{{< math_block >}}
\begin{align*}  
&\overline{v_{7}}=\frac{\partial y}{\partial v_{7}}=1\\  
&\overline{v_{6}}=\overline{v_{7}}\frac{\partial v_{7}}{\partial v_{6}}=\overline{v_{7}}\times1=1\\  
&\overline{v_{5}}=\overline{v_{7}}\frac{\partial v_{7}}{\partial v_{5}}=\overline{v_{7}}\times(-1)=-1\\  
&\overline{v_{4}}=\overline{v_{6}}\frac{\partial v_{6}}{\partial v_{4}}=\overline{v_{6}}\times1=1\\  
&\overline{v_{3}}=\overline{v_{6}}\frac{\partial v_{6}}{\partial v_{3}}=\overline{v_{6}}\times1=1\\  
&\overline{v_{2}}=\overline{v_{5}}\frac{\partial v_{5}}{\partial v_{2}}+\overline{v_{4}}\frac{\partial v_{4}}{\partial v_{2}}=\overline{v_{5}}\times\cos v_{2}+\overline{v_{4}}\times v_{1}\\  
&\overline{v_{1}}=\overline{v_{4}} \frac{\partial v_{4}}{\partial v_{1}}+\overline{v_{3}} \frac{\partial v_{3}}{\partial v_{1}}=\overline{v_{4}}\times v_{2}+ \overline{v_{3}} \frac{1}{v_{1}}=5+\frac{1}{2}=5.5

\end{align*}
{{< /math_block >}}

æ¥ä¸‹æ¥æˆ‘ä»¬è®¨è®ºä¸€ä¸‹ä¸ºä»€ä¹ˆå‰æ–‡ä¸­$\overline{v_2}$ç”±ä¸¤éƒ¨åˆ†ç»„æˆã€‚è€ƒè™‘å¦‚ä¸‹ä¸€ä¸ªè®¡ç®—å›¾ï¼š
![image.png](https://pics.zhouxin.space/202406071612078.png?x-oss-process=image/quality,q_90/format,webp)

$y$å¯ä»¥è¢«è§†ä½œå…³äº$v_2$å’Œ$v_3$çš„å‡½æ•°ï¼Œå³$y = f(v_2, v_3)$ï¼Œé‚£ä¹ˆï¼š
{{< math_block >}}
\overline{v_{1}}=\frac{\partial y}{\partial v_{1}}=\frac{\partial f(v_{2},v_{3})}{\partial v_{2}}\frac{\partial v_{2}}{\partial v_{1}}+\frac{\partial f(v_{2},v_{3})}{\partial v_{3}} \frac{\partial v_{3}}{\partial v_{1}}=\overline{v_{2}} \frac{\partial v_{2}}{\partial v_{1}}+\overline{v_{3}} \frac{\partial v_{3}}{\partial v_{1}}
{{< /math_block >}}
å› æ­¤ï¼Œå®šä¹‰partial adjoint $\overline{v_{i\to j}} = \overline{v_j} \frac{\partial v_j}{\partial v_i}$ï¼Œé‚£ä¹ˆ$\overline{v_i}$å¯ä»¥è¡¨ç¤ºä¸ºï¼š
{{< math_block >}}
\overline{\nu_i}=\sum_{j\in next(i)}\overline{\nu_{i\rightarrow j}}
{{< /math_block >}}

## åå‘æ¨¡å¼å¾®åˆ†ç®—æ³•çš„å®ç°
åŸºäºä»¥ä¸Šåˆ†æï¼Œå¯ä»¥å†™å‡ºå¦‚ä¸‹çš„å®ç°åå‘æ¨¡å¼å¾®åˆ†ç®—æ³•çš„ä¼ªä»£ç ï¼š
![image.png](https://pics.zhouxin.space/202406071612188.png?x-oss-process=image/quality,q_90/format,webp)

å…¶ä¸­`node_to_grad`æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œä¿å­˜ç€æ¯ä¸ªèŠ‚ç‚¹çš„partial adjointå€¼ã€‚ç”±äºæ˜¯æŒ‰ç…§é€†æ‹“æ‰‘åºåˆ—éå†çš„èŠ‚ç‚¹ï¼Œå› æ­¤å¯ä»¥ä¿è¯å½“éå†åˆ°$i$æ—¶ï¼Œæ‰€æœ‰ä»¥$i$ä¸ºè¾“å…¥çš„èŠ‚ç‚¹ï¼ˆkèŠ‚ç‚¹æ‰€åœ¨çš„é›†åˆï¼‰éƒ½å·²è¢«éå†å®Œæ¯•ï¼Œå³$\overline{v_k}$å·²ç»è®¡ç®—å‡ºæ¥ã€‚

é‚£ä¹ˆpartial adjointå€¼ä½¿ç”¨ä»€ä¹ˆæ•°æ®ç»“æ„ä¿å­˜å‘¢ï¼Ÿä¸€ä¸ªå¸¸è§çš„æ€è·¯æ˜¯ä½¿ç”¨é‚»æ¥çŸ©é˜µï¼Œä½†æ˜¯è¿™ä¸ªçŸ©é˜µä¸­æœ‰å¤§é‡å…ƒç´ æ˜¯ä¸å­˜åœ¨äº†ï¼Œç©ºé—´æµªè´¹å¾ˆå¤§ã€‚æˆ‘ä»¬å¯ä»¥åœ¨åŸæœ‰è®¡ç®—å›¾çš„åŸºç¡€ä¸Šè¿›è¡Œæ‹“å±•æ¥ä¿å­˜partial adjointå’Œadjonitzhiä¹‹é—´çš„è®¡ç®—å…³ç³»ã€‚

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œé»‘è‰²éƒ¨åˆ†æ˜¯åŸè¡¨è¾¾å¼çš„è®¡ç®—å›¾ï¼Œçº¢è‰²éƒ¨åˆ†æ˜¯å°†adjointå’Œpartial adjountçš„è®¡ç®—å›¾ï¼š
![image.png](https://pics.zhouxin.space/202406071611419.png?x-oss-process=image/quality,q_90/format,webp)




ä½¿ç”¨è®¡ç®—å›¾ï¼Œé™¤äº†èƒ½å¤ŸèŠ‚çœå†…å­˜å¤–ï¼Œè¿˜èƒ½æ¸…æ¥šçš„çœ‹åˆ°æ­£å‘è®¡ç®—çš„ä¸­é—´ç»“æœå’Œåå‘è®¡ç®—ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œè¿›è€Œä¼˜åŒ–è®¡ç®—ã€‚

## åå‘æ¨¡å¼adå’Œåå‘ä¼ æ’­çš„åŒºåˆ«
![image.png](https://pics.zhouxin.space/202406071817738.png?x-oss-process=image/quality,q_90/format,webp)

åå‘ä¼ æ’­ï¼š
- åœ¨åå‘è®¡ç®—è¿‡ç¨‹ä¸­ä½¿ç”¨ä¸å‰å‘ä¼ æ’­å®Œå…¨ç›¸åŒçš„è®¡ç®—å›¾
- åº”ç”¨äºç¬¬ä¸€ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶

åå‘ADï¼š
- ä¸ºadjointåœ¨è®¡ç®—å›¾ä¸­åˆ›å»ºç‹¬ç«‹çš„èŠ‚ç‚¹
- è¢«åº”ç”¨äºç°ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶

ç°ä»£æ™®éåº”ç”¨åå‘ADçš„åŸå› ï¼š
- æŸäº›æŸå¤±å‡½æ•°æ˜¯å…³äºæ¢¯åº¦çš„å‡½æ•°ï¼Œè¿™ç§æƒ…å†µä¸‹éœ€è¦è®¡ç®—æ¢¯åº¦çš„æ¢¯åº¦ï¼Œä½†åå‘ä¼ æ’­å°±ä¸èƒ½è®¡ç®—æ­¤ç±»æƒ…å†µï¼Œè€Œåœ¨åå‘ADä¸­åªè¦å¢åŠ ä¸€ä¸ªèŠ‚ç‚¹ååœ¨æ­¤è®¡ç®—æ¢¯åº¦å³å¯ï¼›
- åå‘ADä¼˜åŒ–ç©ºé—´æ›´å¤§ã€‚

## è€ƒè™‘Tensorçš„åå‘æ¨¡å¼AD
å‰é¢éƒ½æ˜¯åœ¨å‡è®¾ä¸­é—´å˜é‡æ˜¯æ ‡é‡çš„åŸºç¡€ä¸Šè®¨è®ºçš„ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°†å…¶æ¨å¹¿åˆ°Tensorä¸Šã€‚

é¦–å…ˆæ¨å¹¿adjointï¼Œå®šä¹‰å¯¹äºä¸€ä¸ªTensor$Z$ï¼Œå…¶adjoint$\overline{Z}$ä¸ºï¼š
{{< math_block >}}
=\begin{bmatrix}\frac{\partial y}{\partial Z_{1,1}}&...&\frac{\partial y}{\partial Z_{1,n}}\\...&...&...\\\frac{\partial y}{\partial Z_{m,1}}&...&\frac{\partial y}{\partial Z_{m,n}}\end{bmatrix}
{{< /math_block >}}
é‰´äº
{{< math_block >}}
\begin{align*}Z_{ij}&=\sum_kX_{ik}W_{kj}\\v&=f(Z)\end{align*}
{{< /math_block >}}
é‚£ä¹ˆåœ¨è®¡ç®—$\overline{X_{i,k}}$æ—¶ï¼Œéœ€è¦å°†æ‰€æœ‰è®¡ç®—å›¾ä¸Šä»¥$X_{i,k}$ä¸ºè¾“å…¥çš„èŠ‚ç‚¹éƒ½æ‰¾å‡ºæ¥ï¼Œå³$Z$çš„ç¬¬$i$è¡Œçš„æ¯ä¸ªå…ƒç´ ã€‚å› æ­¤$\overline{X_{i,k}}$çš„è®¡ç®—å…¬å¼ä¸ºï¼š
{{< math_block >}}
\overline{X_{i,k}}=\sum_{j}\frac{\partial Z_{i,j}}{\partial X_{i,k}}\bar{Z}_{i,j}=\sum_{j}W_{k,j}\bar{Z}_{i,j}
{{< /math_block >}}
ä¸Šè¿°å…¬å¼è®°ä¸ºçŸ©é˜µå½¢å¼ä¸ºï¼š
{{< math_block >}}
\overline X = \overline Z W^T
{{< /math_block >}}

# Lecture 5: Automatic Differentiation Implementation
è¿™è®²ä¸»è¦ä»‹ç»æˆ‘ä»¬hwä¸­è¦å®ç°çš„needleçš„æ€»ä½“æ¡†æ¶ï¼Œé¡¹ç›®ä¸­å·²ç»™å‡ºäº†çº¦1000è¡Œä»£ç ã€‚

## autograd.py
autogradä¿å­˜ä¸å®ç°è‡ªåŠ¨å¾®åˆ†ç›¸å…³çš„ä»£ç ã€‚

`Value`ç±»å¯¹åº”è®¡ç®—å›¾ä¸Šçš„èŠ‚ç‚¹ï¼Œå…¶æ•°æ®æˆå‘˜åŒ…æ‹¬ï¼š
```python
class Value:
    """A value in the computational graph."""

    # trace of computational graph
    op: Optional[Op]
    inputs: List["Value"]
    # The following fields are cached fields for
    # dynamic computation
    cached_data: NDArray
    requires_grad: bool
```
`op`ç”¨äºä¿å­˜è¯¥èŠ‚ç‚¹çš„è¿ç®—ç¬¦ï¼Œ`inputs`ä¿å­˜è¯¥è¿ç®—ç¬¦çš„æ“ä½œæ•°ï¼Œ`cached_data`ä¿å­˜è¯¥èŠ‚ç‚¹çš„æ•°å€¼ï¼Œå…¶æ•°æ®ç»“æ„å› å¹³å°ä¸åŒè€ŒåŒºåˆ«ã€‚

## ops
æœ¬èŠ‚ä¸»è¦ä»‹ç»needleåº“çš„ä»£ç ç»“æ„ï¼Œç¬”è®°ç›¸å½“è‰ç‡ï¼Œå»ºè®®çœ‹åŸè§†é¢‘ã€‚

opsæ–‡ä»¶å¤¹ï¼ˆ2023ç‰ˆæœ¬ï¼‰æˆ–è€…op.pyï¼ˆ2022ï¼‰ç‰ˆæœ¬ä¿å­˜å„ç§ç®—å­çš„å®ç°ã€‚
`Op`ç±»è§„å®šäº†ä¸¤ä¸ªå¿…é¡»è¦å®ç°çš„æ¥å£ï¼š
```python
class Op:
    """Operator definition."""

    def compute(self, *args: Tuple[NDArray]):
        """Calculate forward pass of operator.

        Parameters
        ----------
        input: np.ndarray
            A list of input arrays to the function

        Returns
        -------
        output: nd.array
            Array output of the operation

        """
        raise NotImplementedError()

    def gradient(
        self, out_grad: "Value", node: "Value"
    ) -> Union["Value", Tuple["Value"]]:
        """Compute partial adjoint for each input value for a given output adjoint.

        Parameters
        ----------
        out_grad: Value
            The adjoint wrt to the output value.

        node: Value
            The value node of forward evaluation.

        Returns
        -------
        input_grads: Value or Tuple[Value]
            A list containing partial gradient adjoints to be propagated to
            each of the input node.
        """
        raise NotImplementedError()
```
`compute`æ¥å£ç”¨äºæè¿°è¯¥è¿ç®—ç¬¦å®æ–½çš„è¿ç®—ï¼Œ`gradient`æè¿°è¯¥è¿ç®—ç¬¦å¯¹åº”çš„æ¢¯åº¦è®¡ç®—æ–¹å¼ã€‚

# Lecture 6: Fully connected network, optimization, initialization
## å…¨è¿æ¥ç½‘ç»œ
ä¹‹å‰æˆ‘ä»¬è®¨è®ºçš„å…¨è¿æ¥ç½‘ç»œéƒ½æ˜¯ä¸å«åæ‰§é¡¹çš„ï¼ˆä¸ºäº†æ–¹ä¾¿è¿›è¡Œæ‰‹åŠ¨å¾®åˆ†ï¼‰ï¼Œæœ¬ç« å°†ä»‹ç»çœŸæ­£çš„MLPã€‚å…¶é€šè¿‡è¿­ä»£çš„è¿‡ç¨‹è¿›è¡Œå®šä¹‰ï¼š
{{< math_block >}}
\begin{align*}  
&z_{i+1} = \sigma_i(W_i^Tz_i+b_i), \ \ \ i=1,...,L\\  
&h_\theta(x) = z_{L+1}\\  
&z_1 = x  
\end{align*}
{{< /math_block >}}
ä¸Šè¿°æ¨¡å‹ä¸­ï¼Œå¯ä¼˜åŒ–çš„å‚æ•°é›†åˆä¸º$\theta = \{W_{1:L}, b_{1:L} \}$ã€‚$\sigma_i(x)$æ˜¯éçº¿æ€§çš„æ¿€æ´»å‡½æ•°ï¼Œç‰¹åˆ«çš„ï¼Œæœ€åä¸€å±‚æ²¡æœ‰æ¿€æ´»å‡½æ•°ï¼Œå³$\sigma_L (x)= x$ã€‚

è¿­ä»£çš„è¡¨è¾¾å¼å†™æˆçŸ©é˜µå½¢å¼ä¸ºï¼š
{{< math_block >}}
\begin{align*}  
Z_{i+1} = \sigma_i(Z_iW_i+1b_i^T)  
\end{align*}
{{< /math_block >}}
å…¶ä¸­ï¼Œ$1$è¡¨ç¤ºä¸€ä¸ªè¡¨ç¤ºä¸€ä¸ªå…¨1çš„åˆ—å‘é‡ï¼Œç”¨äºå°†åˆ—å‘é‡$b_i^T$å¹¿æ’­åˆ°ä¸çŸ©é˜µ$Z_iW_i$ç›¸åŒ¹é…çš„å½¢çŠ¶ã€‚

åœ¨å®é™…å®ç°è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸ç”¨æµªè´¹ç©ºé—´å»æ„é€ è¿™æ ·ä¸€ä¸ªå…¨1åˆ—å‘é‡ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨å¹¿æ’­ç®—å­ã€‚åœ¨NumPyæœ‰è®¸å¤šè‡ªåŠ¨çš„å¹¿æ’­æ“ä½œï¼Œä½†æ˜¯åœ¨æˆ‘ä»¬å®ç°çš„needleåº“ä¸­ï¼Œè¿™ä¸€æ“ä½œæ›´åŠ æ˜¾å¼ï¼Œä¾‹å¦‚å¯¹äº$(n\times 1) \to (m \times n)$ï¼Œè¦æ‰§è¡Œçš„æ“ä½œä¸º`A.reshape((1, n)).broadcast_to((m, n))`ã€‚

## ä¼˜åŒ–
å¯¹äºæœ‰ç›‘ç£çš„æ·±åº¦å­¦ä¹ ä»»åŠ¡ï¼Œä¸€èˆ¬çš„ä¼˜åŒ–ç›®æ ‡ä¸ºï¼š
{{< math_block >}}
\mathop{\text{minimize}}_{\theta} \ \ f(\theta) = \frac{1}{m}\sum_{i=1}^m{l(h_\theta(x^{(i)},y^{(i)}))}
{{< /math_block >}}
æ¥ä¸‹æ¥å°†ä»‹ç»å‡ å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•ã€‚

- æ¢¯åº¦ä¸‹é™ gradient desecent
æ¢¯åº¦ä¸‹é™æ³•ä¹‹å‰å‡ èŠ‚è¯¾è®²è¿‡äº†ï¼Œè¿™é‡Œç›´æ¥ç»™å‡ºå…¶æ•°å­¦è¡¨è¾¾å¼ï¼š
{{< math_block >}}
\theta_{t+1} = \theta_t - \alpha \nabla_\theta f(\theta_t)
{{< /math_block >}}
å…¶ä¸­ï¼Œ$t$è¡¨ç¤ºè¿­ä»£æ¬¡æ•°ã€‚

å­¦ä¹ ç‡è¿™ä¸€å‚æ•°å¯¹äºè¯¥æ–¹æ³•æ ¼å¤–é‡è¦ï¼Œä¸åŒçš„å­¦ä¹ ç‡çš„è¡¨ç°ç›¸å·®å¾ˆå¤§å¾ˆå¤§ï¼š
![image.png](https://pics.zhouxin.space/202406161006752.png?x-oss-process=image/quality,q_90/format,webp)

ä¸Šå›¾å±•ç¤ºäº†å¤§å­¦ä¹ ç‡å’Œå°å­¦ä¹ ç‡çš„è¿­ä»£è¿‡ç¨‹ï¼Œå¦‚æœç›®æ ‡å‡½æ•°å†å¤æ‚ä¸€ç‚¹ï¼Œé‚£ä¹ˆç¡®å®šåˆé€‚çš„å­¦ä¹ ç‡å°±ä¼šå˜å¾—æ›´åŠ å¤æ‚ã€‚æ¥ä¸‹æ¥å°†ä»‹ç»ä¸€äº›ä¸åŒçš„æ–¹æ³•ï¼Œå®ƒä»¬å„æœ‰å…¶æ”¶æ•›è¡Œä¸ºã€‚

å¯¹äºæ¢¯åº¦ä¸‹é™æ³•çš„æ”¹è¿›ï¼Œæœ‰ä¸¤ç§æ–¹æ¡ˆï¼šæ¢¯åº¦è®¡ç®—çš„å˜ç§å’Œéšæœºçš„å˜ç§ã€‚é¦–å…ˆä»‹ç»ç¬¬ä¸€ç±»ã€‚

- ç‰›é¡¿æ³• Newton's Method
ç‰›é¡¿å‘ä½¿ç”¨äºŒæ¬¡æ›²é¢å¯¹ä¸€ä¸ªé«˜ç»´å‡½æ•°åšè¿‘ä¼¼ï¼Œå› æ­¤å…¶æ”¶æ•›é€Ÿåº¦æ˜¾è‘—å¿«äºä¸€é˜¶é€¼è¿‘çš„æ¢¯åº¦ä¸‹é™æ³•ã€‚å…¶è¿­ä»£å…¬å¼ä¸ºï¼š
{{< math_block >}}
\theta_{t+1} = \theta_t - \alpha(\nabla_\theta^2f(\theta_t))^{-1}\nabla_\theta f(\theta_t)
{{< /math_block >}}
å…¶ä¸­ï¼Œ$(\nabla_\theta^2f(\theta_t))^{-1}$æ˜¯*Hessian*çŸ©é˜µçš„é€†çŸ©é˜µã€‚*Hessian*çŸ©é˜µæ¯ä¸ªå…ƒç´ éƒ½æ˜¯äºŒé˜¶å¯¼æ•°ï¼Œå…¶å…·ä½“å®šä¹‰ä¸ºï¼š
{{< math_block >}}
\nabla_\theta^2f(\theta_t) = H=\begin{bmatrix}\frac{\partial^2f}{\partial x_1^2}&\frac{\partial^2f}{\partial x_1\partial x_2}&\cdots&\frac{\partial^2f}{\partial x_1\partial x_n}\\\frac{\partial^2f}{\partial x_2\partial x_1}&\frac{\partial^2f}{\partial x_2^2}&\cdots&\frac{\partial^2f}{\partial x_2\partial x_n}\\\vdots&\vdots&\ddots&\vdots\\\frac{\partial^2f}{\partial x_n\partial x_1}&\frac{\partial^2f}{\partial x_n\partial x_2}&\cdots&\frac{\partial^2f}{\partial x_n^2}\end{bmatrix}
{{< /math_block >}}
å¯¹äºäºŒæ¬¡å‡½æ•°ï¼Œç‰›é¡¿æ³•å¯ä»¥ä¸€æ¬¡ç»™å‡ºæŒ‡å‘æœ€ä¼˜ç‚¹çš„æ–¹å‘

è¿™ä¸€æ–¹æ³•å¹¿æ³›ç”¨äºä¼ ç»Ÿå‡¸ä¼˜åŒ–é¢†åŸŸï¼Œä½†æ˜¯å¾ˆå°‘ç”¨äºæ·±åº¦å­¦ä¹ ä¼˜åŒ–ã€‚æœ‰ä¸¤ä¸ªä¸»è¦åŸå› ï¼š1) HessiançŸ©é˜µæ˜¯$n\times n$çš„ï¼Œå› æ­¤å‚æ•°é‡ç¨å¾®å¤§ä¸€ç‚¹å…¶è®¡ç®—ä»£ç éƒ½éå¸¸éå¸¸ææ€–ï¼›2) å¯¹äºéå‡¸ä¼˜åŒ–ï¼ŒäºŒé˜¶æ–¹æ³•æ˜¯å¦æ›´æœ‰æ•ˆè¿˜æœ‰å¾…å•†æ¦·ã€‚

- åŠ¨é‡æ¢¯åº¦ä¸‹é™æ³• Momentum
åœ¨æ™®é€šæ¢¯åº¦ä¸‹é™æ³•ä¸­ï¼Œå¦‚æœå­¦ä¹ ç‡å¤ªå¤§ï¼Œå°±ä¼šå‡ºç°æ¥å›æ¨ªè·³çš„æƒ…å†µï¼Œå¦‚æœå¯¹å‰å‡ æ¬¡æ¢¯åº¦å–å¹³å‡ï¼Œåˆ™å¯èƒ½æ”¹å–„è¿™ä¸€æƒ…å†µã€‚

åŠ¨é‡æ³•æ­£æ˜¯å¯¹æ¢¯åº¦å–æŒ‡æ•°ç§»åŠ¨å¹³å‡[^1]çš„æ–¹æ¡ˆï¼Œå…·ä½“æ¥è¯´æœ‰ï¼š
{{< math_block >}}
\begin{align*}  
&u_{t+1} = \beta u_t +(1-\beta)\nabla_\theta f(\theta_t)\\  
&\theta_{t+1} = \theta_t - \alpha u_{t+1}  
\end{align*}
{{< /math_block >}}
è¯¥æ–¹æ³•å¯è§†åŒ–è¿‡ç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨è¾ƒå¤§å­¦ä¹ ç‡çš„æƒ…å†µä¸‹ï¼Œå…¶ç›¸æ¯”æ¢¯åº¦ä¸‹é™æ³•ä¼˜åŒ–æ›²çº¿æ›´ä¸ºå¹³æ»‘ã€‚
![image.png](https://pics.zhouxin.space/202406161114979.png?x-oss-process=image/quality,q_90/format,webp)

- æ— ååŠ¨é‡æ³• Unbiasing momentum
å‰ä¸€ç« èŠ‚å®é™…ä¸Šæœ‰ä¸€ä¸ªå°ç‘•ç–µã€‚å¦‚æœ$u_0$åˆå§‹åŒ–ä¸º0ï¼Œé‚£ä¹ˆç¬¬ä¸€æ¬¡è¿›è¡Œæ›´æ–°æ˜¯çš„æ¢¯åº¦å€¼æ˜¯æ­£å¸¸æ›´æ–°çš„$(1-\beta)$å€ï¼Œå› æ­¤å…¶å‰æœŸçš„æ”¶æ•›è¿‡ç¨‹ä¼šç¨æ…¢ï¼Œéšç€è¿­ä»£çš„è¿›è¡Œï¼Œå…¶æ•ˆåº”ä¼šé€æ¸å‡å¼±ã€‚

ä¸ºäº†ä¿®æ­£å…¶å½±å“ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å‚æ•°æ›´æ–°è¿‡ç¨‹ä¸­å¯¹åŠ¨é‡è¿›è¡Œç¼©æ”¾ï¼Œå…·ä½“æ¥è¯´ï¼š
{{< math_block >}}
\theta_{t+1} = \theta_{t} - \frac{\alpha u_{t+1}}{1-\beta^{t+1}}
{{< /math_block >}}
å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¿®æ­£ä»¥åå…¶å‰æœŸçš„æ›´æ–°é€Ÿåº¦è¦å¿«äº†ä¸å°‘ã€‚
![image.png](https://pics.zhouxin.space/202406161128045.png?x-oss-process=image/quality,q_90/format,webp)

- Nesterov momentum
Nesterovæ˜¯æ¢¯åº¦ä¸‹é™ä¸­ä¸€ä¸ªéå¸¸æœ‰æ•ˆçš„â€œtrickâ€ï¼Œå…¶åœ¨ä¼ ç»Ÿmomentumçš„åŸºç¡€ä¸Šï¼Œå°†è®¡ç®—å½“å‰ä½ç½®çš„æ¢¯åº¦æ”¹ä¸ºè®¡ç®—ä¸‹ä¸€æ­¥ä½ç½®çš„æ¢¯åº¦ã€‚å³ï¼š
{{< math_block >}}
u_{t+1} = \beta u_t +(1-\beta)\nabla_\theta f(\theta_t - \alpha u_t)
{{< /math_block >}}
å…³äºå…¶ä¸ºå•¥æœ‰æ•ˆï¼Œçœ‹åˆ°äº†ä¸¤ç¯‡æ–‡ç« ã€‚ç¬¬ä¸€ç¯‡[^2]é€šè¿‡æ¨å¯¼è®¤ä¸ºè¯¥æ–¹æ¡ˆå¯¹äºŒé˜¶å¯¼æ•°è¿›è¡Œäº†è¿‘ä¼¼ï¼Œå› æ­¤å…¶æ”¶æ•›é€Ÿåº¦æ›´å¿«ï¼›ç¬¬äºŒç¯‡[^3]è®¤ä¸ºå…¶èƒ½å¤Ÿæ›´å¥½åœ°æ„ŸçŸ¥æœªæ¥ä½ç½®çš„æ¢¯åº¦ï¼Œåœ¨æœªæ¥æ¢¯åº¦å¾ˆå¤§æ—¶æ”¾æ…¢æ­¥å­ã€‚

ä¸çœ‹å¹¿å‘Šçœ‹ç–—æ•ˆï¼Œå¯¹æ¯”æ™®é€šMomentumï¼Œè¯¥æ–¹æ³•çš„æ”¶æ•›é€Ÿåº¦è¦å¿«å¾—å¤šã€‚æ®è¯´å…¶ä¹Ÿæ›´é€‚åˆä¸€ä¸ªæ·±åº¦ç½‘ç»œã€‚
![image.png](https://pics.zhouxin.space/202406161306619.png?x-oss-process=image/quality,q_90/format,webp)

- Adam
Adamæ˜¯ä¸€ç§è‡ªé€‚åº”çš„æ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚ä¸åŒå‚æ•°å…¶å¯¹åº”çš„æ¢¯åº¦ä¹‹é—´çš„å¤§å°å·®å¼‚å¯èƒ½å¾ˆå¤§ï¼ŒAdamå¯¹æ­¤çš„è§£å†³æ–¹æ¡ˆæ˜¯æä¾›ä¸€ä¸ªç¼©æ”¾å› å­ï¼Œæ¢¯åº¦å€¼å°åˆ™å°†å…¶ç¼©æ”¾å¾—å¤§ä¸€ç‚¹ï¼Œå³ï¼š
{{< math_block >}}
\begin{align*}  
&u_{t+1} = \beta_1 u_t + (1-\beta_1)\nabla_\theta f(\theta_t)\\  
&v_{t+1} = \beta_2 v_t + (1-\beta_2)(\nabla_\theta f(\theta_t))^2  &\text{å¹³æ–¹ä¸ºé€å…ƒç´ è¿ç®—}\\  
&\theta_{t+1} = \theta_t - \frac{\alpha u_{t+1}}{\sqrt{v_{t+1}}+\epsilon} & \text{æ‰€æœ‰å…ƒç´ å‡ä¸ºé€å…ƒç´ è¿ç®—}\\  
\end{align*}
{{< /math_block >}}
Adamåœ¨å®è·µä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼Œåœ¨ç‰¹å®šä»»åŠ¡ä¸Šï¼Œå…¶å¯èƒ½ä¸æ˜¯æœ€ä½³çš„ä¼˜åŒ–å™¨ï¼ˆå¦‚ä¸‹å›¾ï¼‰ï¼Œä½†åœ¨å¤§éƒ¨åˆ†ä»»åŠ¡ä¸Šï¼Œå…¶éƒ½èƒ½æœ‰ä¸é”™çš„å¯ä»¥ä½œä¸ºåŸºçº¿çš„è¡¨ç°ã€‚
![image.png](https://pics.zhouxin.space/202406161602224.png?x-oss-process=image/quality,q_90/format,webp)

æ¥ä¸‹æ¥å°†ä»‹ç»éšæœºå˜ç§ã€‚éšæœºå˜ç§æ˜¯åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­åŠ å…¥äº†éšæœºå˜é‡ï¼ˆå™ªå£°ï¼‰ï¼Œä¾‹å¦‚æ¯æ¬¡ä½¿ç”¨æ•°æ®é›†çš„ä¸€ä¸ªå­é›†å¯¹å‚æ•°è¿›è¡Œæ›´æ–°ã€‚
- éšæœºæ¢¯åº¦ä¸‹é™ Stochastic gradient descent
éšæœºæ¢¯åº¦ä¸‹é™æ­£æ˜¯æ¯æ¬¡ä½¿ç”¨æ•°æ®é›†çš„ä¸€ä¸ªå­é›†å¯¹å‚æ•°è¿›è¡Œæ›´æ–°ï¼Œå³ï¼š
{{< math_block >}}
\theta_{t+1} = \theta_t - \frac{\alpha}{|B|}\sum_{i\in B}\nabla_\theta l(h_\theta(x^{(i)},y^{i}))
{{< /math_block >}}

çœ‹ä¸Šå»SGDçš„è¿­ä»£æ¬¡æ•°æ¯”æ¢¯åº¦ä¸‹é™è¦å¤šå¾—å¤šï¼Œä½†æ˜¯å…¶æ¯è½®è¿­ä»£çš„è®¡ç®—ä»£ä»·éƒ½è¦å°çš„å¤šï¼ŒåŒæ—¶
![image.png](https://pics.zhouxin.space/202406161624584.png?x-oss-process=image/quality,q_90/format,webp)

å°½ç®¡åœ¨å‡¸ä¼˜åŒ–ä¸Šå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ç»™äº†å¾ˆç›´è§‚çš„æ„Ÿå—ï¼Œä½†éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ·±åº¦å­¦ä¹ å¹¶ä¸æ˜¯å‡¸ä¼˜åŒ–æˆ–è€…äºŒæ¬¡å‡½æ•°ï¼Œè¿™äº›ä¼˜åŒ–æ–¹æ³•åœ¨æ·±åº¦å­¦ä¹ ä¸Šçš„åº”ç”¨ä¸åœ¨å‡¸ä¼˜åŒ–ä¸Šçš„æ•ˆæœå¯èƒ½å®Œå…¨ä¸åŒã€‚

## åˆå§‹åŒ–
å‚æ•°çš„åˆå§‹å€¼å¦‚ä½•ç¡®å®šï¼Ÿè¿™æ˜¯ä¸ªå¥½é—®é¢˜ã€‚

åœ¨å‡¸ä¼˜åŒ–ä¸­ï¼Œå°å°å°†æ‰€æœ‰å‚æ•°åˆå§‹åŒ–ä¸º0ï¼Œå¦‚æœåœ¨ç¥ç»ç½‘ç»œä¸­ä¹Ÿè¿™ä¹ˆåšï¼Œé‚£ä¹ˆæ¯ä¸€å±‚çš„è¾“å‡ºéƒ½æ˜¯0ï¼Œæ±‚å¾—çš„æ¢¯åº¦ä¹Ÿéƒ½æ˜¯0ğŸ™ã€‚å…¨0æ˜¯è¿™ä¸ªæ¨¡å‹çš„ä¸€ä¸ªä¸åŠ¨ç‚¹ï¼Œæ¨¡å‹å°†æ°¸è¿œå¾—ä¸åˆ°æ›´æ–°ã€‚

- åˆå§‹åŒ–å‚æ•°å¯¹æ¢¯åº¦çš„å½±å“å¾ˆå¤§
ä¸€ç§è‡ªç„¶çš„æƒ³æ³•æ˜¯å¯¹å‚æ•°è¿›è¡Œéšæœºåˆå§‹åŒ–ï¼Œä¾‹å¦‚æŒ‰ç…§å¤šå…ƒæ­£æ€åˆ†å¸ƒè¿›è¡Œåˆå§‹åŒ–ã€‚ä½†æ˜¯ï¼Œåˆ†å¸ƒä¸­å‚æ•°çš„é€‰æ‹©å¯¹äºæ¢¯åº¦çš„å½±å“å¯èƒ½ä¼šç›¸å½“å¤§ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
![image.png](https://pics.zhouxin.space/202406161659652.png?x-oss-process=image/quality,q_90/format,webp)
éšç€å±‚æ•°çš„å¢åŠ ï¼Œå¦‚æœæ¿€æ´»å€¼èŒƒæ•°å˜åŒ–çš„å¤ªå‰§çƒˆï¼Œä¼šå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸æˆ–è€…æ¶ˆå¤±é—®é¢˜ï¼Œå¦‚æœæ¢¯åº¦å€¼è¿‡å¤§æˆ–è€…è¿‡å°ï¼Œä¹Ÿä¼šå¯¼è‡´è¿™äº›é—®é¢˜ã€‚

- æƒé‡çš„åœ¨è®­ç»ƒè¿‡ç¨‹çš„å˜åŒ–å¯èƒ½å¾ˆå°
å¯èƒ½å­˜åœ¨è¿™æ ·ä¸€ä¸ªè¯¯åŒºï¼šæ— è®ºåˆå§‹å€¼å¦‚ä½•é€‰æ‹©ï¼Œè¿™äº›å‚æ•°æœ€ç»ˆéƒ½ä¼šæ”¶æ•›åˆ°æŸä¸ªåŒºåŸŸé™„è¿‘ã€‚äº‹å®å¹¶éå¦‚æ­¤ï¼Œæ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­æƒé‡çš„å˜åŒ–å¹¶éå¦‚æ­¤å‰§çƒˆã€‚

- ä¸ºä»€ä¹ˆ2/nåœ¨å‰é¢æ˜¯ä¸ªåˆé€‚çš„åˆå§‹åŒ–å‚æ•°
è¿™é‡Œç›´æ¥ä½¿ç”¨gptå¯¹è¿™é¡µpptçš„è§£é‡Š
> è€ƒè™‘ç‹¬ç«‹çš„éšæœºå˜é‡ ğ‘¥âˆ¼ğ‘(0,1)xâˆ¼N(0,1) å’Œ ğ‘¤âˆ¼ğ‘(0,1ğ‘›)wâˆ¼N(0,n1â€‹)ï¼Œå…¶ä¸­ ğ‘¥x æ˜¯è¾“å…¥ï¼Œğ‘¤w æ˜¯æƒé‡ã€‚
> 
> #### æœŸæœ›å’Œæ–¹å·®
> 
> - ğ¸[ğ‘¥â‹…ğ‘¤ğ‘–]=0E[xâ‹…wiâ€‹]=0
> - Var[ğ‘¥â‹…ğ‘¤ğ‘–]=1ğ‘›Var[xâ‹…wiâ€‹]=n1â€‹
> 
> å› æ­¤ï¼Œå¯¹äº ğ‘¤ğ‘‡ğ‘¥wTxï¼š
> 
> - ğ¸[ğ‘¤ğ‘‡ğ‘¥]=0E[wTx]=0
> - Var[ğ‘¤ğ‘‡ğ‘¥]=1Var[wTx]=1ï¼ˆæ ¹æ®ä¸­å¿ƒæé™å®šç†ï¼Œğ‘¤ğ‘‡ğ‘¥wTxÂ æœä»Â ğ‘(0,1)N(0,1)ï¼‰
> 
> ### æ¿€æ´»å€¼çš„æ–¹å·®
> 
> å¦‚æœä½¿ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œå¹¶ä¸” ğ‘§ğ‘–âˆ¼ğ‘(0,ğ¼)ziâ€‹âˆ¼N(0,I)ï¼Œåˆ™ ğ‘Šğ‘–âˆ¼ğ‘(0,1ğ‘›ğ¼)Wiâ€‹âˆ¼N(0,n1â€‹I)ï¼Œé‚£ä¹ˆï¼š
> 
> ğ‘§ğ‘–+1=ğ‘Šğ‘–ğ‘§ğ‘–zi+1â€‹=Wiâ€‹ziâ€‹
> 
> ### ReLU éçº¿æ€§
> 
> å¦‚æœä½¿ç”¨ ReLU éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œç”±äº ReLU ä¼šå°†ä¸€åŠçš„ ğ‘§ğ‘–ziâ€‹ åˆ†é‡è®¾ä¸ºé›¶ï¼Œå› æ­¤ä¸ºäº†è¾¾åˆ°ç›¸åŒçš„æœ€ç»ˆæ–¹å·®ï¼Œéœ€è¦å°† ğ‘Šğ‘–Wiâ€‹ çš„æ–¹å·®å¢åŠ ä¸€å€ã€‚å› æ­¤ï¼š
> 
> ğ‘Šğ‘–âˆ¼ğ‘(0,2ğ‘›ğ¼)Wiâ€‹âˆ¼N(0,n2â€‹I)
> 
> è¿™å°±æ˜¯æ‰€è°“çš„ Kaiming æ­£æ€åˆå§‹åŒ–ï¼ˆHe åˆå§‹åŒ–ï¼‰ï¼Œå®ƒç‰¹åˆ«é€‚ç”¨äº ReLU æ¿€æ´»å‡½æ•°ã€‚

# Lecture 7: Neural Network Library Abstractions
è¿™èŠ‚è¯¾ä¸»è¦ä»‹ç»å¦‚ä½•ä½¿ç”¨æˆ‘ä»¬çš„needleåº“æ¥å®ç°ä¸€äº›ç®€å•çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæ„é€ ä¸€äº›å°ç»„ä»¶ã€‚
## ç¨‹åºæŠ½è±¡
ç°ä»£æˆç†Ÿçš„æ·±åº¦å­¦ä¹ åº“æä¾›äº†ä¸€äº›APIï¼Œç«™åœ¨ä»Šå¤©çš„è§†è§’ï¼Œè¿™äº›APIéƒ½æ˜¯éƒ½æ˜¯æ°åˆ°å¥½å¤„çš„ã€‚é€šè¿‡æ€è€ƒä¸ºä»€ä¹ˆè¦è¿™æ ·è®¾è®¡æ¥å£ï¼Œå¯ä»¥è®©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£æ·±åº¦å­¦ä¹ åº“åœ¨è¿›è¡Œç¨‹åºæŠ½è±¡æ—¶çš„å†…éƒ¨é€»è¾‘ã€‚

é¦–å…ˆå‡ ä¸ªç»å…¸çš„æ·±åº¦å­¦ä¹ æ¡†æ¶è¿›è¡Œåˆ†æï¼ŒåŒ…æ‹¬Caffeã€TensorFlowå’ŒPyTorchã€‚
- Caffe 1.0 ï¼ˆ2014ï¼‰
åœ¨Caffeä¸­ï¼Œä½¿ç”¨Layerè¿™ä¸€æ¦‚å¿µæ¥è¡¨ç¤ºç¥ç»ç½‘ç»œä¸­çš„ä¸€ä¸ªä¸ªå°æ¨¡å—ï¼Œé€šè¿‡æ‹¼æ¥å’Œæ›¿æ¢Layerï¼Œå¯ä»¥å®ç°å¿«é€Ÿæ„é€ å’Œä¿®æ”¹ç¥ç»ç½‘ç»œï¼Œå¹¶ä½¿ç”¨åŒä¸€å¥—ä»£ç è¿›è¡Œè®­ç»ƒã€‚

Layerç±»æä¾›äº†`forward`å’Œ`backward`ä¸¤ä¸ªæ¥å£ï¼š
```python
class Layer:
	def forward(bottom, top):
		pass

	def backward(top, propagate_down, bottom):
		pass
```

`forward`è´Ÿè´£å°†æ¥è‡ªbottomçš„æ•°æ®è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œç„¶åå°†æ•°æ®ä¿å­˜åˆ°topä¸­ã€‚åœ¨`backward`æ¥å£ä¸­ï¼Œtopä¿å­˜æ¥è‡ªè¾“å‡ºçš„æ¢¯åº¦ï¼Œ`propagate_down`ç”¨ä»¥æŒ‡ç¤ºæ˜¯å¦è¦å¯¹å…¶æ±‚æ¢¯åº¦ï¼Œbottomç”¨äºå­˜æ”¾æ¢¯åº¦ã€‚

åœ¨Caffeä¸­ï¼Œè®¡ç®—æ¢¯åº¦æ˜¯â€œå°±åœ°â€å®Œæˆçš„ï¼Œè€Œéåœ¨è®¡ç®—å›¾ä¸Šæ–°å¢é¢å¤–çš„èŠ‚ç‚¹ã€‚ä½œä¸ºç¬¬ä¸€ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç›´æ¥è®¡ç®—æ¢¯åº¦çš„æ€æƒ³æ˜¯æœ´ç´ ä½†æ˜¯ç¬¦åˆç›´è§‰çš„ã€‚

- TensorFlow 1.0 ï¼ˆ2015ï¼‰
ä½œä¸ºç¬¬äºŒä»£æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå…¶åœ¨å¼•å…¥äº†è®¡ç®—å›¾çš„æ¦‚å¿µã€‚åœ¨è®¡ç®—å›¾ä¸­ï¼Œåªè¦å®šä¹‰å‰å‘è®¡ç®—çš„è®¡ç®—æ–¹å¼ï¼Œå½“éœ€è¦è®¡ç®—æ¢¯åº¦æ—¶ï¼Œç›´æ¥å¯¹è®¡ç®—å›¾è¿›è¡Œæ‹“å±•å³å¯ã€‚ä¸€ä¸ªç®€çŸ­å®ä¾‹ä¸ºï¼š
```python
import tensorflow as tf

v1 = tf.Variable()
v2 = tf.exp(v1)
v3 = v2 + 1
v4 = v2 * v3

sess = tf.Session()
value4 = sess.run(v4, feed_dict = {v1: numpy.array([1])})
```

ä»¥ä¸Šä»£ç `v1~4`ä»…ä»…æ˜¯å ä½ç¬¦ï¼Œç”¨äºæ„å»ºè®¡ç®—å›¾ï¼Œåœ¨æ²¡æœ‰è¾“å…¥ä¼ å…¥å‰å¹¶æ²¡æœ‰å€¼ã€‚é€šè¿‡ä¼šè¯æ¥è·å–æŸä¸ªè¾“å…¥çš„æƒ…å†µä¸‹è¾“å‡ºçš„å€¼ã€‚

ä¸Šè¿°è¿‡ç¨‹è¢«ç§°ä¸ºå£°æ˜å¼ç¼–ç¨‹ã€‚å³è®¡ç®—å›¾åœ¨å®šä¹‰æ—¶å¹¶ä¸ä¼šç«‹å³æ‰§è¡Œï¼Œè€Œæ˜¯ç­‰åˆ°ä¼šè¯ï¼ˆsessionï¼‰è¿è¡Œæ—¶æ‰æ‰§è¡Œã€‚è¿™ç§æ–¹å¼çš„ä¼˜ç‚¹æœ‰ï¼šä»£ç åˆ†åŒºï¼Œå¯è¯»æ€§é«˜ï¼›è¿è¡Œå‰è®¡ç®—å›¾å·²çŸ¥ï¼Œå¯ä»¥é’ˆå¯¹æ€§ä¼˜åŒ–ï¼›é€šè¿‡ä¼šè¯ä¾¿äºå®ç°åˆ†å¸ƒå¼è®¡ç®—

- PyTorch (needle)
PyTorchä½¿ç”¨çš„æ˜¯å‘½ä»¤å¼ç¼–ç¨‹ï¼Œç›¸æ¯”å£°æ˜å¼ç¼–ç¨‹ï¼Œå‘½ä»¤å¼ç¼–ç¨‹åœ¨æ„å»ºè®¡ç®—å›¾æ—¶å°±å·²ç»æŒ‡å®šå…¶å€¼ã€‚
```python
import needle as ndl

v1 = ndl.Tensor([1])
v2 = ndl.exp(v1)
v3 = v2 + 1
v4 = v2 * v3

```
å‘½ä»¤å¼ç¼–ç¨‹å¯ä»¥å¾ˆæ–¹ä¾¿åœ°ä¸PythonåŸç”Ÿæ§åˆ¶æµè¯­å¥ç»“åˆåœ¨ä¸€èµ·ï¼Œä¾‹å¦‚ï¼š
```python
if v4.numpy() > 0.5:
	v5 = v4 * 2
else:
	v5 = v4
```

tf1.0çš„æ•ˆç‡æ›´é«˜ï¼Œé€‚åˆæ¨ç†å’Œéƒ¨ç½²ã€‚PyTorch1.0åˆ™æ›´é€‚åˆå¼€å‘å’Œdebugã€‚

## é«˜çº§æ¨¡å—åŒ–åº“ç»„ä»¶
å¦‚ä½•ä½¿ç”¨æ·±åº¦å­¦ä¹ åº“æ¥å®ç°æ·±åº¦å­¦ä¹ å‘¢ï¼Ÿåœ¨hw1ä¸­æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªä¸ªåº•å±‚ç®—å­æ¥æ­å»ºæ¨¡å‹å’Œå®ç°è®­ç»ƒè¿‡ç¨‹ï¼Œä½†è¿™æ ·å¼€å‘å¤ªä½æ•ˆäº†ã€‚æ·±åº¦å­¦ä¹ æœ¬èº«æ˜¯å¾ˆæ¨¡å—åŒ–çš„ï¼šç”±æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–æ–¹æ³•ä¸‰éƒ¨åˆ†ç»„æˆã€‚ä¸ä½†å¦‚æ­¤ï¼Œæ¨¡å‹æœ¬èº«ä¹Ÿæ˜¯é«˜åº¦æ¨¡å—åŒ–çš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨å®ç°æ·±åº¦å­¦ä¹ åº“æ—¶ï¼Œå¿…é¡»ç²¾å¿ƒè®¾è®¡å¥½æ¥å£ï¼Œä»¥ä¾¿æ”¯æŒè¯¥æ¨¡å—åŒ–çš„ç‰¹æ€§ã€‚

åœ¨PyTorchä¸­ï¼Œæœ‰ä¸€ç±»å«åš`nn.Module`ï¼Œå¯¹åº”çš„å°±æ˜¯æ¨¡å‹ä¸­ä¸€ä¸ªä¸ªå°çš„å­æ¨¡å—ï¼Œå…¶ç‰¹ç‚¹æ˜¯ä»¥TensoråŒæ—¶ä½œä¸ºè¾“å…¥å’Œè¾“å‡ºã€‚æŸå¤±å‡½æ•°ä¹Ÿæ»¡è¶³è¿™ä¸€ç‰¹æ€§ï¼Œå…¶å¯ä»¥è¢«è§†ä¸ºä¸€ä¸ªæ¨¡å—ã€‚

å¯¹äºä¼˜åŒ–å™¨ï¼Œå…¶ä½œç”¨æ˜¯è¾“å…¥ä¸€ä¸ªæ¨¡å‹ï¼Œå¯¹è¯¥æ¨¡å‹ä¸­çš„å‚æ•°æŒ‰ç…§æŸä¸€è§„åˆ™è¿›è¡Œæ›´æ–°ã€‚

ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæœ‰äº›æ¨¡å‹è¿˜å…·æœ‰æ­£åˆ™é¡¹ï¼Œå…¶æœ‰ä¸¤ç§å®ç°æ–¹å¼ï¼š
- ä½œä¸ºæŸå¤±å‡½æ•°çš„ä¸€éƒ¨åˆ†è¿›è¡Œå®ç°
- ç›´æ¥æ•´åˆè¿›ä¼˜åŒ–å™¨ä¸­

å‚æ•°åˆå§‹åŒ–åŒæ ·å¾ˆé‡è¦ï¼Œå…¶ä¸€èˆ¬åœ¨æ„å»º`nn.Module`ä¸­æŒ‡å®šã€‚

æ•°æ®åŠ è½½ä¹Ÿæ˜¯ä¸€ä¸ªå¾ˆé‡è¦çš„æ¨¡å—ã€‚æ•°æ®åŠ è½½ä¸­è¿˜ç»å¸¸å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†å’Œå¢å¼ºã€‚

å„ç»„ä»¶ä¹‹é—´æ•°æ®æµå›¾å¦‚ä¸‹æ‰€ç¤ºï¼š
![image.png](https://pics.zhouxin.space/202406200916559.png?x-oss-process=image/quality,q_90/format,webp)

# Lecture 8: Neural Network Implementation
## ä¿®æ”¹Tensorçš„dataåŸŸ
åœ¨å®ç°SGDæ—¶ï¼Œç”±äºå­˜åœ¨å¤šä¸ªbatchï¼Œå¯èƒ½ä¼šåœ¨ä¸€ä¸ªå¾ªç¯é‡Œå¯¹å¾…å­¦ä¹ å‚æ•°è¿›è¡Œæ›´æ–°ï¼Œå³ï¼š
```python
for _ in range(iterations):
	w -= lr * grad
```

æ­£å¦‚åœ¨[CMU 10-414 Assignments å®éªŒç¬”è®° > SGD for a two-layer neural network]({{< relref "CMU%2010-414%20Assignments%20%E5%AE%9E%E9%AA%8C%E7%AC%94%E8%AE%B0.md" >}}#sgd-for-a-two-layer-neural-network)è¸©è¿‡çš„å‘é‚£æ ·ï¼Œç›´æ¥ä½¿ç”¨Tensorä¹‹é—´çš„ç®—å­è¿›è¡Œå‚æ•°æ›´æ–°ä¼šå¯¼è‡´æ¯æ¬¡æ›´æ–°éƒ½ä¼šåœ¨è®¡ç®—å›¾ä¸Šå¢åŠ ä¸€ä¸ªæ–°çš„èŠ‚ç‚¹wï¼Œè¿™ä¸ªèŠ‚ç‚¹å…·æœ‰Opå’Œinputsï¼Œä¸¥é‡æ‹–ç´¯åå‘ä¼ æ’­é€Ÿåº¦ã€‚

ä¸ºäº†é¿å…æ¯æ¬¡æ›´æ–°å‚æ•°æ—¶éƒ½åœ¨è®¡ç®—å›¾ä¸Šç•™ä¸‹ä¸€ä¸ªéœ€è¦æ±‚æ¢¯åº¦çš„èŠ‚ç‚¹ï¼Œneedleåº“æä¾›äº†`Tensor.data()`æ–¹æ³•ï¼Œç”¨äºåˆ›å»ºä¸€ä¸ªä¸`Tensor`å…±äº«åŒä¸€ä¸ªåº•å±‚dataçš„èŠ‚ç‚¹ï¼Œä½†å…¶ä¸å­˜åœ¨Opå’Œinputsï¼Œä¹Ÿä¸ç”¨å¯¹å…¶è¿›è¡Œæ±‚å¯¼ã€‚

å› æ­¤ï¼Œå¯ä»¥ä½¿ç”¨`Tensor.data`æ–¹æ³•ï¼Œåœ¨ä¸å¹²æ‰°è®¡ç®—å›¾åå‘ä¼ æ’­çš„å‰æä¸‹å¯¹å‚æ•°è¿›è¡Œæ­£å¸¸çš„æ›´æ–°ï¼Œå³ï¼š
```python
w.data -= lr * grad.data
```

## æ•°å€¼ç¨³å®šæ€§
æ¯ä¸ªæ•°å€¼åœ¨å†…å­˜ä¸­çš„å­˜å‚¨ç©ºé—´éƒ½æ˜¯æœ‰é™çš„ï¼Œå› æ­¤ä¿å­˜çš„æ•°å€¼çš„èŒƒå›´å’Œç²¾åº¦éƒ½æ˜¯æœ‰é™çš„ï¼Œè®¡ç®—è¿‡ç¨‹ä¸­éš¾å…å‡ºç°æº¢å‡ºæˆ–è€…ç²¾åº¦ä¸¢å¤±çš„æƒ…å†µï¼Œåœ¨å®ç°ç®—å­æ—¶ï¼Œå¿…é¡»è€ƒè™‘åˆ°æ•°å€¼ç¨³å®šæ€§çš„é—®é¢˜ã€‚

ä¾‹å¦‚ï¼Œåœ¨softmaxå…¬å¼ä¸­ï¼Œç”±äºæŒ‡æ•°è¿ç®—çš„å­˜åœ¨ï¼Œæ•°å€¼å¾ˆæœ‰å¯èƒ½å°±ä¸Šæº¢äº†ï¼Œä¸€ä¸ªä¿®æ­£æ–¹å¼æ˜¯åœ¨è¿›è¡Œsoftmaxè¿ç®—å‰ï¼Œæ¯ä¸ªå…ƒç´ éƒ½å‡å»è¾“å…¥çš„æœ€å¤§å€¼ï¼Œä»¥é˜²æ­¢ä¸Šæº¢ã€‚å³ï¼š
{{< math_block >}}
z_i = \text{softmax}(x_i) = \frac{\exp(x_i -c)}{\sum_k {\exp(x_k-c)}}
{{< /math_block >}}
å…¶ä¸­ï¼Œ$c = \max(x)$ã€‚

ç±»ä¼¼çš„ï¼Œå…¶å®ƒç®—å­ä¹Ÿè¦è€ƒè™‘ç›¸åº”çš„ç¨³å®šæ€§é—®é¢˜ã€‚

## Parameter ç±»
`Parameter`ç±»ç”¨äºè¡¨ç¤ºå¯å­¦ä¹ çš„å‚æ•°ï¼Œå…¶æ˜¯`Tensor`çš„å­ç±»ã€‚ç›¸æ¯”`Tensor`ç±»ï¼Œè¿™ä¸ªç±»ä¸å¿…å†å¼•å…¥æ–°çš„è¡Œä¸ºæˆ–è€…æ¥å£ï¼Œå› æ­¤å…¶å®ç°å¾ˆç®€å•ï¼š
```python
class Parameter(ndl.Tensor):
Â  Â  """parameter"""
```

## Module ç±»
`Module`ç±»ç”¨äºè¡¨ç¤ºç¥ç»ç½‘ç»œä¸­ä¸€ä¸ªä¸ªå­æ¨¡å—ã€‚å…¶å…·æœ‰å¦‚ä¸‹æ¥å£ï¼š
- `parameters`ï¼šè·å–æ¨¡å—ä¸­æ‰€æœ‰å¯å­¦ä¹ å‚æ•°
- `__call__`ï¼šè¿›è¡Œå‰å‘ä¼ æ’­
åœ¨å®ç°æ—¶ï¼Œå®šä¹‰äº†ä¸€ä¸ªè¾…åŠ©å‡½æ•°`_get_params`ç”¨äºæå–ä¸€ä¸ªæ¨¡å—ä¸­çš„æ‰€æœ‰å¯å­¦ä¹ å‚æ•°ã€‚
```python
def _get_params(value):
    if isinstance(value, Parameter):
        return [value]
    if isinstance(value, dict):
        params = []
        for k, v in value.items():
            params += _get_params(v)
        return params
    if isinstance(value, Module):
        return value.parameters()
    return []

class Module:
    def parameters(self):
        return _get_params(self.__dict__)

    def __call__(self, *args, **kwargs):
        return self.forward(*args, **kwargs)
```

### Optimizer ç±»
`Optimizer`ç±»ç”¨äºä¼˜åŒ–æ¨¡å‹ä¸­å¯å­¦ä¹ å‚æ•°ï¼Œå…¶æœ‰ä¸¤ä¸ªå…³é”®æ¥å£ï¼š
- `reset_grad`ï¼šé‡ç½®æ¨¡å‹ä¸­å¯å­¦ä¹ å‚æ•°çš„gradå­—æ®µ
- `step`ï¼šæ›´æ–°å‚æ•°å€¼
`reset_grad`å®ç°æ¯”è¾ƒç®€å•ï¼Œ`step`æ–¹æ³•åˆ™ä¾èµ–äºä¼˜åŒ–ç®—æ³•çš„å…·ä½“å®ç°ï¼š
```python
class Optimizer:
    def __init__(self, params):
        self.params = params

    def reset_grad(self):
        for p in self.params:
            p.grad = None

    def step(self):
        raise NotImplemented()
```

# Lecture 9: Normalization and Regularization
## Normalization
åœ¨å‰é¢å‡ è®²æåˆ°è¿‡ï¼Œå‚æ•°åˆå§‹å€¼çš„é€‰æ‹©å¯¹äºæ¨¡å‹çš„è®­ç»ƒå¾ˆé‡è¦ï¼Œä¸æ°å½“çš„åˆå§‹å€¼å‚æ•°ä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±æˆ–è€…çˆ†ç‚¸ğŸ’¥ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œå½“è®­ç»ƒå®Œæˆåï¼Œè¿™äº›æ¢¯åº¦å’Œå‚æ•°å€¼å¤§å°ä»æœ‰åˆå§‹å€¼å·®ä¸å¤šï¼Œè¿™æ›´å¼ºè°ƒäº†åˆå§‹å€¼çš„é‡è¦æ€§ã€‚
![image.png](https://pics.zhouxin.space/202407051309612.png?x-oss-process=image/quality,q_90/format,webp)

ä¸ºäº†ä¿®å¤è¿™ä¸€é—®é¢˜ï¼Œå¼•å…¥äº†layer normalizationã€‚å…¶æ€æƒ³å°±æ˜¯å¯¹æ¿€æ´»å±‚çš„è¾“å‡ºè¿›è¡Œæ ‡å‡†åŒ–ï¼Œå³å°†è¾“å‡ºå‡å»æœŸæœ›åé™¤ä»¥æ ‡å‡†å·®ï¼š
{{< math_block >}}
\begin{align*}  
\hat{z}_{i+1} &= \sigma_i (W_i^Tz_i+b_i)\\  
z_{i+1} &=\frac{\hat{z}_{i+1} - E(\hat{z}_{i+1})}{Var(\hat{z}_{i+1})+\epsilon}  
\end{align*}
{{< /math_block >}}
ä¸Šè¿°æŠ€å·§ç›®å‰å·²ç»å¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œä½†åœ¨å®è·µä¸­ï¼Œåº”ç”¨layer normä¼šå¯¼è‡´æ¨¡å‹éš¾ä»¥æ”¶æ•›åˆ°ä¸€ä¸ªå¾ˆå°çš„losså€¼ã€‚

å¦å¤–ä¸€ç§æŠ€å·§æ˜¯batch normã€‚layer normæ˜¯å¯¹æ¯ä¸€ä¸ªsampleï¼ˆzçš„æ¯ä¸€è¡Œï¼‰åšå½’ä¸€åŒ–ï¼Œè€Œbatch normå¯¹æ¯ä¸€åˆ—å½’ä¸€åŒ–ã€‚è¿™ä¸€æ–¹æ³•ä½¿å¾—æ¯ä¸ªbatchçš„æ‰€æœ‰æ ·æœ¬éƒ½ä¼šå¯¹è¯¥batchä¸­æŸä¸ªæ ·æœ¬çš„æ¨ç†ç»“æœæœ‰å½±å“ï¼Œå› æ­¤åœ¨è¿›è¡Œæ¨ç†æ—¶ï¼Œbatch normä¸­çš„å½’ä¸€åŒ–çš„å‚æ•°åº”è¯¥ä½¿ç”¨æ•´ä¸ªè®­ç»ƒé›†ä¸Šçš„å‚æ•°ï¼Œè€Œéæ¨ç†æ—¶è¾“å…¥æ ·æœ¬çš„batchå‚æ•°ã€‚

## Regularization
æ­£åˆ™åŒ–ç”¨äºå¯¹æŠ—è¿‡æ‹Ÿåˆï¼Œæ‰€è°“è¿‡æ‹Ÿåˆæ˜¯æŒ‡æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šæ€§èƒ½éå¸¸å¥½ï¼Œä½†åœ¨æµ‹è¯•æœºä¸Šæ³›åŒ–æ€§èƒ½å¾ˆå·®ã€‚æ­£åˆ™åŒ–å°±æ˜¯é™åˆ¶å‚æ•°å¤æ‚åº¦çš„è¿‡ç¨‹ï¼Œå¯ä»¥åˆ†ä¸ºæ˜¾å¼æ­£åˆ™å’Œéšå¼æ­£åˆ™ã€‚

éšå¼æ­£åˆ™åŒ–æ˜¯æŒ‡ç°æœ‰ç®—æ³•æˆ–æ¶æ„åœ¨ä¸æ˜¾å¼æ·»åŠ æ­£åˆ™åŒ–é¡¹çš„æƒ…å†µä¸‹ï¼Œè‡ªç„¶åœ°å¯¹å‡½æ•°ç±»è¿›è¡Œé™åˆ¶ã€‚å…·ä½“æ¥è¯´ï¼Œéšå¼æ­£åˆ™åŒ–é€šè¿‡ä»¥ä¸‹æ–¹å¼å®ç°ï¼š
- **ç®—æ³•çš„å›ºæœ‰ç‰¹æ€§**ï¼šä¾‹å¦‚ï¼Œéšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰ç­‰ä¼˜åŒ–ç®—æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªå¸¦æŸäº›æ­£åˆ™åŒ–æ•ˆæœã€‚è™½ç„¶æˆ‘ä»¬å¹¶æ²¡æœ‰æ˜¾å¼åœ°ä¼˜åŒ–æ‰€æœ‰å¯èƒ½çš„ç¥ç»ç½‘ç»œï¼Œè€Œæ˜¯é€šè¿‡SGDä¼˜åŒ–é‚£äº›åœ¨ç‰¹å®šæƒé‡åˆå§‹åŒ–ä¸‹çš„ç¥ç»ç½‘ç»œã€‚è¿™ç§ä¼˜åŒ–è¿‡ç¨‹æœ¬èº«å¯¹æ¨¡å‹çš„å¤æ‚åº¦è¿›è¡Œäº†é™åˆ¶ã€‚
- **æ¶æ„çš„è®¾è®¡**ï¼šæŸäº›ç½‘ç»œæ¶æ„è®¾è®¡æœ¬èº«å°±å…·æœ‰æ­£åˆ™åŒ–æ•ˆæœã€‚ä¾‹å¦‚ï¼Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„å…±äº«æƒé‡æœºåˆ¶å’Œå±€éƒ¨è¿æ¥ç‰¹æ€§ï¼Œè‡ªç„¶åœ°å‡å°‘äº†æ¨¡å‹å‚æ•°çš„æ•°é‡ï¼Œä»è€Œé™ä½äº†æ¨¡å‹å¤æ‚åº¦ã€‚

æ˜¾å¼æ­£åˆ™åŒ–æŒ‡çš„æ˜¯é€šè¿‡æ˜¾å¼å¾—ä¿®æ”¹æ¨¡å‹ä½¿å…¶èƒ½å¤Ÿé¿å…å¯¹è®­ç»ƒé›†guo

# å‚è€ƒæ–‡æ¡£

[^1]: [æŒ‡æ•°ç§»åŠ¨å¹³å‡EMA\_emaç§»åŠ¨å¹³å‡æ•°æ€ä¹ˆç®—-CSDNåšå®¢](https://blog.csdn.net/qq_36892712/article/details/133774755)
[^2]: [zhuanlan.zhihu.com/p/22810533](https://zhuanlan.zhihu.com/p/22810533)
[^3]: [An overview of gradient descent optimization algorithms](https://www.ruder.io/optimizing-gradient-descent/#Nesterov%20accelerated%20gradient)